{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxFnUmd7iFd3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Rh6EdCWLjvT_",
    "outputId": "05541fa9-3e11-4a01-e396-48de0eb92cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFKNwJyVY_54"
   },
   "source": [
    "**Data Description:**\n",
    "\n",
    "> The Street View House Numbers (SVHN) Dataset \n",
    "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data formatting but comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pt9SURB6Yy3t"
   },
   "source": [
    "**Objective:**\n",
    "\n",
    "The objective of the project is to learn how to implement a simple image classification pipeline based on a deep neural network. The goals of this project are as follows:  \n",
    " \n",
    "**Steps and tasks:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88BOIJ1QYKU2"
   },
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z9QON7iYVEPn",
    "outputId": "8f6459c4-dedf-427d-a31e-509614d679bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5HjXuj2Xhrmo",
    "outputId": "4fea0f51-69b0-4cab-a067-53fb019f3922"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from keras.utils import np_utils \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5_rVYavVUrs"
   },
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bW2fzFKEVU1v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROrr_0YsYsKJ"
   },
   "source": [
    "**1. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-RChQeZhzIF"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Open the file as readonly/content/drive/My Drive/SVHN_single_grey1.h5\n",
    "h5f = h5py.File('/content/drive/My Drive/SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuwfpFuiiFOF"
   },
   "outputs": [],
   "source": [
    "# Load the training, test and validation test\n",
    "X_train= h5f['X_train'][:]\n",
    "y_train1= h5f['y_train'][:]\n",
    "X_test= h5f['X_test'][:]\n",
    "y_test1= h5f['y_test'][:]\n",
    "X_val= h5f['X_val'][:]\n",
    "y_val1= h5f['y_val'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iUjhX8_Z5x_"
   },
   "source": [
    "**2. Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)**\n",
    "\n",
    "**3. Data fetching and understand the train/val/test splits.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jzg1taeyaEVF"
   },
   "source": [
    "**Print shape of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "KndFJhiumTG3",
    "outputId": "cf409895-5431-4b1d-a1cf-d2c201ba3222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(42000,)\n",
      "(18000, 32, 32)\n",
      "(18000,)\n",
      "(60000, 32, 32)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train1.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test1.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vx6dyfYgaEj1"
   },
   "source": [
    "**Reshape features**\n",
    "\n",
    "*   reshape() method gives a new shape to an array without changing its data\n",
    "*   we have used 1024 as it is 32 X 32 dimensions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6pLRNbbP_bOs",
    "outputId": "84c5e12e-5b18-4a17-8c4c-1c6cc2b9b017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(42000,1024)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(18000,1024)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzdRJZzKbFm5"
   },
   "source": [
    "**Normalize features**\n",
    "*   Normalize features from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6Qpxm0rH_0a1",
    "outputId": "ec66e68a-b953-4d92-9162-1274a61ca661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "n-wT7Wk-dXnb",
    "outputId": "a8dc7c75-4263-42d9-e77b-2681e8cad6b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "colab_type": "code",
    "id": "MZLho7xjzM54",
    "outputId": "f0cf751b-498b-4601-c093-e19d3aa5dc45"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOy9SW+k2XEFenIic85kkszkWGSRrK6uUkutblmQ3Lbhjbz2xjC89r/wH7B/gJdeeeONlwbshWHYsGzAtqSW1a2ai1UsMjlkMpM5z9Nb8J3gyVtJ8qOMhwcIvABRVazM77tD3IgTJ+LG9U0mE9y3+3bf7tt9u2/37b79Njf//98duG/37b7dt/t23+7bffv/ut0Dnvt23+7bfbtv9+2+/da3e8Bz3+7bfbtv9+2+3bff+nYPeO7bfbtv9+2+3bf79lvf7gHPfbtv9+2+3bf7dt9+69s94Llv9+2+3bf7dt/u2299C970nw8fPpyMx2NMJhP4fD7Mzc1hfn4eqVQK8/PzmJubw3g8Rq/XQ7fbRblcRrfbRb/fx2g0wtzcHObm5hCPx5FMJpFOp7GysoK5uTn4/X40Gg00m000m03UajXU63U0Gg20Wi34/X74/X4Eg0H4fD4EAgEkk0lks1nkcjk8fvwYS0tLyGQyiMfjmEwmGI1GKBQKKJVKKJfL+Ou//mvfbRPwr//6r3YuPxAIwOeb/orP54Pf77ff9/v9qf9LJpNIJpPY2NhAMBiE3+/HeDwGAIzHYwyHQ/vuYDAAAOsrxzgcDu15nBt+fzKZYDweYzweo1wu4+LiAp1OB8FgEIFAAD/84Q9vHePf/M3fTPh5zjd/+Gwdu77TnQt+juMcj8fo9/sYDocYDAbodrsYj8cYjUY2Bv7J+QgEAgiFQiYb0WgUkUgEiUQCkUjEZIvz8+d//uc3jvFv//ZvJ41GA51Ox747Pz+PeDyOubk5exf77vP5MJlMMJlM0O120Wq10Gw2cX5+jmaziU6ng+FwaM9Jp9PWLz4rFAohGo3aOgDAaDTCcDi0ORiPx1PyxBIQfDfn+c/+7M9uXcO/+7u/m6ofwedPJhMEAgEEAgHbKz6fz+Z6NBphNBrZ+4bD4Ud9459ct36/j8FggMFggOFwaGtbrVZxfn6OYrGIUqmEwWCA0WiEwWBge5V7cmFhAZlMBtFoFHNzc/jLv/zLW8d4cHAwaTabqFar+Od//me8fPkS+/v7KBaLJjc/+tGP8OWXX+J73/sePv30U9tzfr8f4XAY8/PzNhbObyAQgN/vt3lQuQRgeozrxzkDYLrp+fPnOD4+RqFQwNnZmemrWq1mOu/4+PjWMf7FX/zFhGuh89fpdEyPtttt9Pt9+7fuL/70ej0bQyAQMJkMhUL2Ln623+/begcCAczPz0/JMueP8zMej03n6Z4HgJ/97Gc3jrFUKk1cHUr7wWey3z6fD6PRaEqOVRb17/z8cDi0fnP/9vt906l8Hm1PMBi0vTCZTBAMBk0XULZV121sbNy6hr/7u787UdvGfo9GI1SrVdTrdZRKJbTbbXQ6HQAw+7ezs4OlpSXbJ7VaDdVq1faP3+9HKBQymdU55Jr2ej3UajWzn9Vq1cYQDocRiUQQjUYRi8VsD08mE/R6PfT7ffzbv/3brWP8yU9+Mul0Omi322aj+KNrwRaJRKy/qnP4/tFoZLrS7/ebzuLfXZvj2p5YLGYylM1m8fjxYzx58gRffvklwuEwQqHQlD7b2dmZOcYbAQ8Xy+fzIRqNIh6PI51OY3193QxAv99Hs9lEvV5Hu93GcDhEv99HMBhEOBxGMplELpfD0tIScrkcdnd3EYlEMDc3Z8qkWq3i9evXOD09NQPKBeYgA4EA0uk01tbWsL29je9+97vIZrNYXFw0JTeZTFCtVk0he2n6Hnejs123gXWR1Ijpc/kZ9xlUMgBswd33cvNSEfd6PVAI3c/e1FSQer0eWq2WKWsVRo5dhZsKgeNxAQ+VTq/XmwJ0qji1D+wHFU8ymbTNSeUfi8UAYEqIb2p8H+eLxtF9J4CpTTGZTEzRUF65VqPRCKFQCPPz84jFYqY8ORb21Z1nPpNzRMPJNdcNTWPipfHdKnM0mOw/3+kqSpVRBT8q69pXfkeNiCoxBVVqjGa9czAYeJZTlZV2u20Gg8+hU9VoNDAYDAzATSYThMNhew7Ho3uQe4hjp+Pi7vdZSrjdbuPDhw94//49jo6OUKvVrG80Iq4sXNd0LlQe3OYCMwWwruwQ6KiM6nP4XZ0L9ldBBvcE38f1UB15W+P33H3Pxj6rrlGni/+ncqa14gh4OHeDwQDNZtNkYTAYYDweTxl9/n40GplsEDCprtC9elObn59HOBxGNBpFOp2e6g9wqbcbjQb6/b6NiU4eHbtUKoXl5WWkUimsrKx8ZA9mOb0A0O120e12p0BWo9GYskF8BueAn+t0Ouh2u57GuLm5aYCq3++j1WqZfWfjHvL5fAbS+C6ua7fbnWnLVZZ07/B7fI861SpbKysraLfbAC51YygUQq/Xu1VGbwQ8RHaTyQSZTAa7u7t4+PAhnj59ikQigWg0im63i+PjYxweHtoit1otpFIprK2tYXNzE1988QU2NjawurqKpaWlKaTX6/XQbDbx85//HG/fvsX+/j5evnyJRqNhExyNRpFIJPD48WN8/vnn+Oyzz7C7u4tgMIjJZIJGo2EC9fDhQ6ytrXleWFfhKPrU5ioFbiJ6V51OxxQON5Mqj9FoNCX8fJfP50OlUjGPkR4255E/pVLJgEWz2TTB/8lPfnLrGMPhsDEPlUrFGLBCoWBKVJWKKslZXhAwbYC73a4heZf1oGLmO6hU+Jler4d4PI5+v2/eqd/vRzQatTW9rdEIcJ5p/HUNXEPD34VCIVOu4/HYAM54PLa1TKVSpoTJ/vh8PvR6PQyHQwMcbOwz+6MAkf1QUOSlqQGnQqHRp2Hw+Xy2+QF89Bm+n+vL8RHs0llxPTX1nGd5YNwz9Jy5P6gQrzPqs9aR68I+AVfeo+4hZU8VYOv681mUYWUfu92uKU8aEMob56Xf76Pb7eLi4gLv37/H/v4+8vn8FJDiHCvze1NTIKUy4Do6uu+U7VFwQFaPDiRZG/aN36Ex4F4nSONchsPhj/SdGtm7yCkAsxm6n1Wvkp2iDeB88nP8UTDu9q3dbpvObDabU2CfQIjMLdkvnR++f35+Hr1e707jI9BJp9PI5XImM/1+H9Fo1BwnlcNkMolUKoXFxUVks1msra1hfX0d6XQaiUTCnq2AQdkRrnuj0UCtVrNnDwYDVCqVqX3KcSUSCcTjcUQiEXS7XWP1vbQ//MM/NGBSKBRwdHSEw8NDHB0dmb7nPAJAu922PlIWw+EwFhYWEAqFjIWhDWi322bDGo2GOZ7z8/O2/9Rh5X6gDqYt5Nyw3aZrbgQ88/PzJkCJRAKZTAYrKyvIZrOIxWKIRCKo1+uYn5+foiqVjdnZ2cHOzg4ymQwSiYShcQCGjhcWFvDkyROjIavVqm1Yn8+HRCKBtbU1fPLJJ9jZ2cHGxgYikQgajQYuLi7w9u1bCzE8fvwY4XAY8Xjc08LO8m7U+FPRUoGXSiU0m03bTKQQHzx4gHQ6jYWFBaytrZngq9AragdgntY333yDg4MD5PN5W1wqW/7U6/Wp8ILSi7c1Cjy9H3rLrVZralPNajQQSvO7dKYKHZWaUuEa8uEz2Zder4f5+XmbC6W4FbDc1FzAoxtFvz+LuaORm0wmZlj5b3rOkUjE3kMgzefrXFCBq0zpO10WT43KXZrODUOjOh6VOb5T++wyW/Pz8wgEAsbGdDqdj7wwHZOOUcMVLluia+KlsU9UkAy30DjNzc0hnU4jFoshFAoZC8fxcu/QiFKm6EDUajUDAY1Gw/oeDoftZ3FxEfF43NhFGs52u21AYRaIdZmV/0tTR0nnUMMJNAoMq8zNzdmccf77/T46nQ76/b6FyRgSUfnRPfebyKPbd5fpJjBkeAm4AskKVl2ni00dBQKmbreLarVq4yPDpbqERpmMTjgctr2irEI0Gr2TPqUDnk6nsby8bE6DAvx6vW66m8Cc+0NlnCwMgJn7RsOM3AeTycTsC99NlooOWzKZRCaTMUBFgDg3N+dpjMFg0Gy8hj37/T6q1artJdUpXLNwOIxMJoNUKoWlpSVEo1FEo1HbL8PhEBcXF/ZDsMSxUo+qU6AMPueFe3swGNh+dZ2Hj8Z106AV8KRSKWQyGSwvL2NhYcE8eYa9qFS4KIuLi1hdXcX29jY2NzdtIx4fH5un4vP5bEF2d3fNwLx//97CXT7fZZ7M+vo6Hj16hK2tLeRyOaPy8vk8vv76a8zPzyOZTGJhYQGrq6tTqPmmpkqam1E9Do6NYbv379+jVCrh4uIClUrFNtPa2pqh9tFohFwuh8XFRVsI9az5DirTb7/9Fr/85S/x4sULAFfeq4IRUoOzQl+3tXA4bIaRz9b8AK6bjlu9LwqYKlylXfXfSm1qfoXOq87BLBZp1ia6qanS1r+zbzc1KhAaELI+AKYAgetJ0JNSBa+hIrZZniPn1ev42NywkYan+F4COJU3/bsyXgQR9Kp03dz11b67SkWpajcX7C5jJFibm5tDNBq1fpG1iUQiSKfTZuA5Zq4bPUAyisPh0LzBTqeD8/NzYwRKpZLNBw1YMpk0Y0QjROeAeTQE60rNuwyflzWcFTrnnOk6KXPFPcx1I0ijQWEOk+qtcDhsgIAGmPvO3Yfah5v6flNTw6Xe+WAwsLllCIhjIYDku125oQzzZzAYoNFooFqt2rsI/qLRKEajEVqtluk1zglTH2gsuQcikcidWLpIJIJYLIaFhQUDPARiHHexWLSQEA23O5e6x3RPqZHX/Uq5GAwGU7mO3Hej0Wgq1MZcoXQ6jVqtZrrZSyMzPDc3h+XlZQCX+pAMUa/XMydcQWwwGEQymcTy8jLW1tbw4MEDJJNJxGKxqchBoVDA8fExAoEAyuWyrdWspnNF50lZMOpmtVvXtRt3KVFoOBzG5uYmcrmcJXCSVjw4OMCrV6/w/Plz5PN5C0c8fPgQjx8/xqNHjxCNRlEul3FycoJ//Md/tNyRn/zkJ3j69CkePXpkkzo/P4/9/X10Oh3U63X4fD5sbGzg8ePH2Nvbw+LiIvx+P+r1OgqFAvb39/H1118bqtza2jLF6KXRmwemPXBS4K1WCy9evMDBwQE+fPiAg4ODKcXHRuWSSCTw+eef4wc/+AG+/PJL/M7v/A4ikQiCweBHcX4q+GaziUKhgHfv3gHAlCJQxaosy10MCZWM5qBokjGpQb6LjB3HxebmibjxWL//MnFUvTFX+DQk4nqwROvKqHlRso1Gw5LdyaoFAgGT3fn5eVMUAMzj8vl8iEQilvhXrVanvH0mk7ZaLZv7Xq83lXTNBFA+lz8aktH1VgB5l+aCcTUmPp9vKpxKAMD/d0NMatTpYTKEEwqF0G63pxg3GkMqNL6LYGQWCFKj5RWcx2IxU2oLCwuW31UulxEKhZBMJrGysmIOF4Hq/Py8jbXb7ZosMRxFZ+XDhw+W33d2dmZzE4lEkEqlsLCwgEajgYcPH04xEsFgEAsLC+aJ1ut1m4/xeDyVLH1bU/A5C9xfB3QUzDEhnzkq6XR6CvhQ/unYkN1iSCMUChkzAsAAxyxjqHvci7E8Ozuz8RBsMfdwbm4OkUgEuVzOgKJ65Rpad50LlaF6vY5isYiLiwvLLWXIKJFImEwS+NBpJCs4mUymQnpuQu5tLR6Pm7xks1kL13DftFotRCIRc5zIsM3NzaHdbqNer5u+qVarAK6cK93DDMOp40inkvqc/x6Px7ZHFhcXsby8jAcPHiCXyyGTyaBcLpsT4aX9wz/8gz3niy++MCIhnU7jxYsXeP78OUql0hRoZ2Tl8ePHePDgAdbX17G6umosUa/XM92zt7eHYrGI09NTxGIxO2xEUM71Vz2qtgeAOTzqbN0WmrwR8ASDQcTjcWQyGayvr2N5eRnJZBKhUMiMPqmyi4sLdLtdE4aVlRXkcjlks1lEIhHUajVjZQqFAtrtNo6Pj7GysmLx9Gg0amEzItPxeIyFhQX7N8MOVG7NZhPlctkMrZ6y8dIUhFCBMrfo/PwcJycneP78OU5PT+10Bidfv6fhomfPnqHb7eL8/Byj0Qibm5tYXV01xczvc5H0BBAZMvW4qRwIRJig6RXwuODIpUypEFwPn8BPN6Lr2bpxdzfnhgqejJKbG6DgyzUCXlun07Hva26DjsMFte78qGc6K5dA55t91hCfshzuxnTf9Zs0F/Co0WQfFJAAV8wXFQH7Q6VDwMY/+R2uK+dSvSc372dWfoUbTvQ6Zh1DKpVCMplEIpEwRoP6IZlMmhPBPnH9+/0+Go0G6vU66vU6Tk5O7N9HR0d20rFcLtv6hcNhMz6ZTMbmh85VMpnE6uoqAJhRAa5CJZqz9n9pLqvhzqd60mR4CHKoQxiedNeGxnM4HE7pId0r+h01ZATQXoBrrVazZ9OZUsDT7XYtRMy11me7f/JzHH+v17P17PV6BizIGnFMygiQ4dPQkuoFMjNegTnneX5+3uaejCOdJYIW/hCAkllstVp22pb2jH2LRCLGIm1sbFgYNxgMYjgcWv4LgXyj0TBmenFx0UJZBMJ+vx+JRMLAr5f27t07nJ+fo1QqYWlpCYFAAPF4HMvLy/a7aDSKZrNptjYUCiGRSGBlZcVOaNbrdcsx6na7BtKXlpaQSqUQDAZRrVZN/2haBx10ygcdRjecroc2bmu3Ap5EIoFcLvcR4OHG5MRXq1XzEHkyK5vNIpPJGJ1I1qLdbqNUKqFYLKJarRqiI2jJ5XIWOuv3+4amE4mEGXt6cWSC+v2+JQ/TM/XSyCJQ2IDLDdbpdHB2doZXr17h9evXqFaraDQa5uGrYeHkkwE4ODhAtVrF0dERwuEwvvjiCwSDQVOawHQohXR6KpUyj5LeCBsBEVkkwHsyqHqQbqhIgQ8VABkMDVPpaSX+TmPS6gW6Ro8bnABHj8myD7MS9ABvNHq73TYKlsLvKkFt7ON1z+e4aMSU+VNP3AU9DFXxu3cJO97WdE6uy3XQHBh+h6dQFLzp+iro4ef1s+qB63f1VB/f5bISmhvipencpVIppFIpxONx22uRSMSYn0gk8pFhp04ol8soFosoFot4//69GYWTkxMDQo1Gw+Zsbm7OQiSZTMYSLgmqeDKVJ/larRaAyzVnSQyve/G6ubgulKN7iYCcxo19jEQixjLpvuRe5vwx10F1C2VGQY8LbrwcHGDTHE2CnV6vh3a7jVAohH6/b2tKudO9xabvJ+jmiSwyutRZHBP1i4I3MpXMpaHcaziaIcrb2AE2ZWAIOslgEAhpmQBlXM/Pz9FqtXBxcYFGo2HsEOURuMwRoj2Ix+NIJBL2zF6vZ8CReaSNRsPkQPN2GPoFLlkpAlAvLZ/PIxaLoVqtYmtry0rKpNNpLC4uYnFx0Q4tMa+RgIenz0KhEE5PT22/dbtdSzuJxWI2Ntr/TqeD09NTy5NTwEMZcIEpdQAPMN22D28FPMvLy3j48CG2t7eRTqeNStYcANKRTCpcW1tDNpudSv4jOnzy5IkpUSbjXlxcoNfrIRaLIZFIYGNjA6enp1bXJ5vNIp1OG2hSo8znk75VZsJL6/V6hsgJyBqNBn7961/jV7/6FZ49e4ZisWjjJYVJpEoAoKcGeFz1w4cP+Pu//3u8evUKX375Jf70T//UWCoqMb/fjx/84AfIZrP46quvpsIF6mVr3QwqXa8Z9zTcLoPisjwKYCiQjL/GYjFj63iqQxUj+0vgx/wJMjulUslynqh8SNPzlIQaSY7bi7KtVCpTxptro+E1Mjc+n888XDe/RT1DpX5JU/OEHGWBdDMBoQIdvoveKfuga3IXMKCeGeeIa8V9QGVLMMB3hMNh27OTycQAC4GqC4goKwpYXOp4fn5+KoGb8sOSFGSA7xK+U5Yuk8lgaWkJi4uL5jXH43EsLi4ilUpZjo2GJZiMzCPk7969w8uXL9FsNtFut9FqtWy+qVCpuwiEnj9/jk6nYwmezFuMRqNWY4VH5Tk31WoVlUrF0xi5P9QBcefadRYI5Pr9vskl11sNrs4FAYLWU+I68hnK3OqxdgVM7LP+eVNbXFw0GQFgOqBardr+KZVKCAaDljulgEb3Ct83NzeHVquFWq2Go6Mjc67T6bSxgDx+PRgMDBxw/5MVoZ5RdoeA6S6Ah2E6luJw94km+fL91I1cRy2LMJlMrPYc2U2GqAjWGE7l+9TRcuv2UGbInM9i0G5r6XTa5ujs7MwIjLW1NTuYk0qlLL+NeoZkx9zcHIbDId68eYPT01MUi0V0u12Ew2GkUilMJhPs7e1ha2sLe3t7tuZHR0c2BgXimiOn+WuaF+RFPm9NWla6mxOp1LMqQn6WdBxDNFwUJnqRqaHgENGxw5FIBPF4HPF43AyUUlYaeuBGVwNzF4+LcXpFzo1GA4eHh5Z4prkCe3t7Vv8nk8nYQtXrdZydneHs7Mw8yXa7PVVrSD04LtJwOEQul0M0GsXm5qYhVWA6QVSNEwAcHh6ap3lbU4/EpaxdGpvsDcMHW1tbSKVSdiJBT8W4SXf84djoffDEAr08Nl0jDQkoSPGyju1222hlFwBQEZEyppzSqFD2qEA0IZQbnnWhyCZS7ni6gwDcDR1SoboySSN7l6YAXkMbLmBRQEKPXufVZW/4HPWylaHRBFQ+w+fzTRV209Mp/NFcpruc0uKcUY9QVyi45J+cd46f68ncgLOzM1QqFQsBsD+qL4CrBMjxeIxarYZisYhQKIRisYhYLGaAJ5lMWp5Zp9NBp9OxAww8vHFbc0OSLrOjDKfLyrrOChlGshgK5hQk0RkkoFD9QlkneFIdwzW/C2O+vLxsMkaAxr6xhlKlUrH5VEOl86CAi4Dl4uIChULBwrS0JQzn8bsa2lVww7G7BxA4Vq9jZIiMYI7vp36hfFHv6JpxXoCrOmOTyQTNZnMqdKt2k3ZW0w8UYGlYkuNjDpuyuvy8l8Y8KMo6605Rt0QiEQOYrVbLmCTmTvJUFosrBgKBqcT/YrGIpaUlZLPZqbpEzKlkP12ngPNG546yT0dL5XdWuxHwqJHkg/1+v8UFXc+QQsYJUVRGRM9ExGAwaJuQk6CAh8mUmgCqSZ8UHjXAqsS8es70RpnLQ6bm8PDQkqgoiPF4HI8ePcLOzg4ePHiAxcVFSwatVCo4OjqypDllmVTYaexUeDOZjHlGAGxOXOGkseER07OzM09jVNbIDVEoUNHNE4/HsbCwgJ2dnY8AHjcjP6uGnSCXTBkTTguFwkeelCo3V0hV0G9r7XbbxqaMC4GNFshiH6mMmOSqR8tdwMP14lFYhja41ro2wBUg17AZ5WEWfe+l6Tzoc91cJQ1REMCzuYBn1h4m9e6yDpwbjlETJ12aXD3MWcbluqZ9YjmAWCw2xWDoD3DFLKoHzXBWqVSyMLTWF6KsqAFkX5kTGAqFUC6Xsb6+bgUy1YOu1WqoVCqoVCro9/uWyOxlHVU2XKbH/R3/fR3Yof7RkJcm2BOg0djoqRoaVOpr1r5SwKOhLy/ruLS0ZH3mIQLuQaYvdLtdJBIJSyhWQDKLgRgOh2i1WqhUKjg/P7dDKRreVCdG9Zgyqe4cu3vWK+BhUcxWq2VAWnWga6yVqdO5VfvYarXMOVD9qqybsjb6OR0v55qAR5lerrmXpmw75YgRFNp4n89nrF0qlbLvMrQ1NzeHXC5nQJWyNxwOUS6XrYAngSvZXO5P3Qe6Npp/yOexJh77d127EfAMh0NLMv7w4YMZZiYOc4G4kSgIjMkR5HCxiBBpPJj8TI+RCtUtoa7UIQWJnjlwtRm5KK4w3dRU6DudDgqFAg4PD3F8fGyZ9cFgEBsbG3j48CF+/OMfWy6TGmzGNr/44gvk83m8efMG+/v7GA6H+Oqrr/B7v/d7pgw090MNvXrUqsS5qNzA5+fnePHiBf7zP//T0xhd1oGbkJuEAIBeO+s4LC4uYnNz05KuGW9laIAGjxuPBpjv4cmfWq1mAIMnwtgnDd/xe+pxe1Gy3W7XSo9zTd28E6Xp9XNUDDy1ocmgNIpkqs7OznB0dGSnZOLxuBUp1NwlKgpXgbqsyl2aerBcP86dmzegHqaC68FgYJ9hsqWyJ8z3cX/U2+QedcfJ9dTQm57289IUOHFceooMgBXd5Fi41nx3o9GwwpqVSmUqoXIWENbTOZw36ioeaWeeH+eK4VoAuLi4wPHxsZ2w9NJUTlxZVx2g+kX1gZ4g5e80cZrPca8G4e9Ul3LPhsNhS4zlnubn78JGMmTdbrdRqVSMOaJ8sXZaIBAw9kxLd7isJQBLFSiVSjg9PcXq6qolxvLZ2nTcCth1/pWN0dwoL42heSbcch+x0blhPxhWUsDM8BRwVd9LE54JABTsEyySbSHQ4vhZrJbvYeiIKQqcWy9N9Qx1YiwWm0ploG2kE08GvFKpWH5ONpvF6enpVETH5/OZI8L5cvMuZwFIftYlVzTxXXXsrHYjKmi32yiXy/D7/VhYWIDf75+6O8T1VHk2n6eb9PQAwRArKBPluwwDAPNamOOj9QxI0atXoHSdi9y9LCw/z/oO5+fnxqKMRiNEo1EsLi5iY2PDAJyeCmHIg3Tfzs4O0uk0dnd3MRgMsLu7i5WVFQDT9DnHrCfFFDzo/HJuBoMBjo6OcHZ2houLC09j1LuRXC9SN78KnZsXQjA0Go2srg+VoypEVd6cGwJXDR+56+R6RWxe1lHBDT+vYQE+x/1/Ur803BoS0xAVj5JeXFygVCohEolgOByiVqshkUig0+kgkUjYel0H1nSMd2V5FFApO6HMnDI3uj+UVXA9QgU27l7U5ylDqUyqG3pxQ1p3YXgUpLmsEhmLcrmMRCJhylffy+O/DCdzX3Is/F4kErHPsvimslv8P/4/jQv7xXecn58jn8/j9PQUhULB0xhd9mxWWEvnlfNOwEfjxnwUyhtllvpRQ80EMNRRnBc3dKnsCJ/NP919edP4aOQ7nY4BZYLTwWCA8/NzZDIZO8btpkZQNrk/9Q43Ms88DKN2Q0EF9awCCepazpcbDYlOLR4AACAASURBVPBqMxjiIfh2UzJmrbeCHe2fOiNky2nI9Y6owWBg8qig3wWjBBTj8djAGIvw3sUuMsJAtp8VmzWERNtLJ2o4HKJareLDhw/WFxYoBGD2g8+gLnOTk9111UagpTZKwf5tcnoj4GGOyHA4xOLiIhKJxFT9AnaAgkrAQEaIyJcVlqvVqsVxSTHzuyp8NJBMHmSyoHqonCROOjB9ZcBdkCwnfTAYmCehl9KFQiGk02msrq7a8UMKGw06wZjf70cul8Pm5qYJKpN+td6DKmK+h+NRpcNGT5vJ0GdnZ1bD4bbGPvK9aph0vjQWrKESFUD3RBYVIudSy/cT2GqinsZxZ62FKn2vTQ0wMF15mU09SA25qFF2x83fE6jz6DJpbB6t5CkxypwL6rSfbp+8jpX9UXqaBkzXw5Wb65gClbFZrI6bG6PzN6vxHWQi3RCMl0Z2hc/j74CrPI5CoWAX9sbj8am15qlNhhq00m4wGLQLHFl5lqwD7+ThepCmp/wS8NCYM1R7enqKw8NDnJ6eenY+dD40ZHgd6OHaa0kIAHaUms6hnhqiIVBZcJ/Jd2tSMz/nMqHKPN3W1ICTxacRJ+AolUpYXV21cDJ1IcfKHzq95XIZpVLJvsfwusqxOlDUcRwb7RD18Xh8WepkFgvrpZFl4UEGnT9ts9ZUmRMy3tTPzJV1AQ8AAzxkm5mEres2Ho9tTgeDAWq1mjH1bHcJaXHfsL4RHT0tYEl2kMxntVrF+/fvTf9Xq1U7uk7Gn2AbmL5iR1lr1TOujadTqlhAIws36dQbAc/FxYUVSVpbW0On05laOIIBJhcGAgErFf3v//7vOD8/x9nZGRKJBKrVKi4uLvD111/bBXzb29tTi0mlUigUcH5+jouLCxwdHRnT8Nlnn2F1ddVitzzJkcvlMB6Pp4o9eT2lpZ4sY/Hn5+dmCH2+y6st6B0qMPP5fHZ6iggdgCWeMbGLG0vjvTQKDOlRobi0tL6vWq3i7OwMX3/9NQ4ODjyf0lJmx0XPXEdldzTRT08JcI40QVPZPgBWc4EeBvMcyNKxTpLSpTpel9r3so7xeNyUhR6D5ak+jW9rscVOp4NGo2Een25sgstWq2X313A8odBl4TayfYFAwIp60SNTQD7L4Kvn7KXp5xR4XMfWKKPles8KdPRUzqzP09N2QeWs/qijoR6tV6OickQPkmvGUyrPnj0zAMY7zug0kHlhlV2+n4BhfX0dGxsbyGazaLVaOD4+thNA7CONBpW3nsoiWP/w4YMVX3vx4oUdNf5NmuuAuGFLglqyPNwjZJ78fr+xsDwB4/f7p1gNABYS4dwp+KYBYkiT+oh7hYbdy15kuE+dWr2Ul4cZqAcI1uhwUD4JRKvVKg4ODuwUHI9bMw9U5ZLzpayizic/64ZjyU64hWGva7y7MRwOTzGJ3PfUO8B0bpCCTTrLBDzUG/Pz88hkMna8nDqGeaJMyC+VSqjVami1WlM6U++VJJOmOT9enQ8yO6zBt7i4iFgshmaziYuLC5ydnRmDF4/HEQ6HrdDnz372M7x79w6ZTAaTycROQAKw0B+/oyfR3HworpXbZ007INjifGsO2sxx3TRoLhQnjB1xPUzXKx4MBlZAqFQqYX5+Hp1OB81mEx8+fECtVrMTJEpFUegYs2UZeCY9HR8f28ZmIuHy8rIBp2g0ipWVFasV5KVxI0wmE6Mq6fFRqTNXg2XL1Rjz791u13IOWJuD9JvS/BpmUdqai+WGdtQQ1Wo15PN5HB8fW6FHL03XSKlAjWG7iJpIvl6vm+JkLQUCX5cl8Pl8log4Ho+tXgZ/6DFrwt0sZe8q/Nuaq2A0fq5GlM9TBlGpWW5AeqL8oaHTcORkMjEQlE6n0W63PwIRwHReCvBxwUqvjWEXt7kgZdbzCUS4X4HZYcBZz1XjOOtzbihN330dLX1d072hIReCmX6/j0KhYBVgWVKCLAdLILgAy++/TFTPZDLI5XLY2NhAs9k0RldPRqqypJGnQ0CGgEw1j9p6da74fA3jaghGQ0sAZsquspP8jK4zx869rmunOoUASj3lyWQyleRMI6Ssppc1dPeMGlvVg6pDXV1H/VOr1ax4ZCAQsEMvCuZUn2r+k8oRdYEb7lWb5nUd3dwrzr3aQa6z7kt3/2hIR+/AYtHAZDI5ZT94IqpWq03pU2VIdPyar3VXtpXFfldWVuz01Gg0Qrlcxvn5Oc7Pz6cK/Kp8MjLD/tCuAleHlzKZDOLxOPx+v+X9sAyNsrzsL0NsXHOSIGozdf6vazcCHi6Ixiddz8D1MCl0vGTzw4cPUwJ1fn5u4R83PEXgUKvVDPS0Wi1Uq1UUi0UcHx9bkT4i/eXlZTx69Ag+32VSIQHPTZna2nRzcGEUSEwmEwM8PGLJZEatJ9NqtawGzPz8vG14Jotx0dTIaRhAN4l6KpokymKGLObktWomPUPOuc67KgH1yqnweKSQfSQg1HCKxnHVc3LBjuZFqYzN+lGFdFtToKIxZs6fKhxleVikEoAxlZprQAPq3sxLMEXWiuPTQmN8r97ErONx8wduazwhqevEZygwmfVcDTsrOL0O8Li/d9/jvs81zL9pU2WssX6yimQ0WNOJ4QQW1dN8Og3JkAZPp9PIZrNYX1+33MBisTgVJtS5UVnV0ALZ6ouLi4+KaN7WyJjR0CnDq4m22h9lCKhHVZcQ0OrRYIa3qEeoVxQQkZl0r19RBonJx5zr25ruERfU6DhoU5RtYSPgoZN8cnICn89ngICMrit3lBcFgXzfLMDjhg+9MjwKTtUuzmJQXYeEn9VQHlkw3lKg9YUYBmL/CCZqtZqFbfXwCO0JHQWde69hSeDytB3vwspms4hGo5Z/xQgMozIKtBSsAld3bNKpJjOztLRkEZNqtWohSwXWlAnXOeYcazRC5/8mJ+vWwoPqsSpdNMv7pqfE3zebTSsKR8EcjUYWAmM1ZVbeJCV9cnKCs7MzlEolo0DPzs7w3//937YRP/vsM0PCDx48sElaXl7+SOBvasoCaOY7Y+Q0hKPRCBcXF3j9+rWF25hXpAscDF7eu5PL5bCysoKnT59ifX3dqlSqseLmUxSu6FRzZo6Pj/Hq1Sv8/Oc/N7Dj1XtmuBGAbSSGbiiI6gUy259H7SuVCiKRiK1Ps9k0AKUF0CKRCNbW1kzoaRQY0tIb22exEcqqXJcEOKutr69bX6hEeZ8N67iQCWCeGb2KwWBglUOZeNxqtdBqtawa+Lt371AqlaYKW3LueTLo6OgInU7HjlZynLqeHDfHexf2Q4+YujlULgDhHGiiLf/fTfYj6GWfZrFtqpzd3C4F6TRuVOIuY3FbIxjQUCpBJ0OLvV7PlKMm4yvDA1yBM1W0uVzOLvnlHV3pdNocLrIeXCf23+e7TLylE8AE2lKphE6nMxV6vq3x+RznaDSyk6Wzwg76XP2MGktWoea9UnQGebhAj60zdMQ9y5NA/CxDwprUTePqxcEiMCIrRg+fbJnmGamDrABOWQI6usvLy8jlcpY3xz2mMst3u/dFKZhU1ovv47qShfDS2G/KhobPdU/SMGueCdk3yqbf75+6nJvXKDExn+uiofVmsznl1CmA5H7XfaHMt5f2e7/3e8hms1hZWbF8q3K5jG+//dby1pRlrNfrBrpZR4h7g6fEIpGIreP29jbi8Tg6nQ7evn2Lw8ND5PN5VCoV+54mOVOXKhbR9AzdJzftxVsZHuAqtHWTR+jSdq6S1Hg0j/UygZCGl2Dn9PQUtVrNEqQJepi8xkJfnFw9BQR4L1gHYIoZUG9EabJqtYrXr1/j8PAQ7969M9BFw+wqeobh8vk8zs/P8fDhQ+zu7uIHP/jBVAVgN2Sg3oIaEVKJZ2dnyOfz5sXcRN1p46bTQpI8zseKmGwau+ect1othEIh22wsxkg2g+G+WCxmOQSj0chOFJDZ4XvcZFmVF9fz8mJIVlZW7DvML6I3xItuOZ/0HCkvDGWlUinMz8+b0azX6xa2KJVKpgzj8fjUOMbjscWuKY9cV5fNm9W8Gkp3D7qUuRuSVEpf59Kl3rkOrsKcFVJUJaPPoPfF+eVn6H163Yvsu4Jdn++qZAV/p6dEOEZNvlUAp3JHdpM/3A/UT+6aKTPrhqLZTz7fKzhXwEPWVMMgXA8FxxwL54Of4f6jE5NMJrG0tGQsCPN2XBngEWPeqk3AQ9BAL5v9VFm5reldhvzeZDKZYkpdFtQF3JPJxA4K0KkMBAJ2UkjtiavrlRUgIJnF6qh8a0jUS6OMqVyORiPTqVw/PpefV8ef4yUYZ2FeOvHMUdLnEIAyX0zDoVxblWHKFg/acE68tN3dXWObeMq61WpZ1IUgXeeE79Q59fuv7shcXV3F8vKylXWhvPB+O96+rvuM41KWR2WZ42JI77Z9eCvgUQ+PL9Gwlm5ABTwan9RTG0T4PF7Ie0L6/b7VtDg5OUG1WjVBp5egIZJOp2OhKyo25mS4iO+mpomA+qOGhDlE3W4X+XzeBNVFlfxhLRCfz4eTkxMUi0XUajXs7u4aY+QKP4ApYVRlOxxeXjpXKBRQLBanjgx6aVwH9zgfC9NRSPmjicmaC1AqlVCtVu0CVQIn3vkSj8exsbFhnh1vMGcSKWVGUbo7B8owsO+3tZWVlY9ycrjhlD3j76iUaZApj5wPhvIuLi5wfn6OcrlsckXAQxnQXCd6LCobN4XlvMoocHVjtGsIXS9HgY7LFihj6Hqj17E77j7nj5ur5DJBnBv+eGnKTPE5BKSUUc6Bevcu4GHT8COdGI5Dc9pUP3EPuk7HdeuoeRxeGvUN2TY37+O6fA9dQ+ByD5HV0csil5eXjW3lKSA1BBpWYPE+Ah4AMwEP2VEv49QTclq3heExFtjTCsKz9gsZvWq1ivF4bIVf6SwqQFfGlW1WGMuVbV1D9zDGTY3P1UrJZFrcI9JkVQh4CIZ0bgnAWZjXBTx06KlL6XxRXlxHmXOpoPiugCeXy9npYjLnZP+4pxUXqO2k08xwczQaxfLyMh4/fmwn7FjTjeSAOtIuE87n67q7Dt1NelbbrYBHUaTSZRQkekj8DBdWqXQ1zDweur6+jlwuZxVM9/f38atf/Qpff/013rx5Y0mFiub12goAlkD16tUrOxXw2WefWajMS1MFqgJDo93r9ZDP56doVy4qaUxN2Gaoh0JXq9Xw7NkzHB0dYWFhAd/97nfx+PFjC725BonzTuqZIZNvv/0WJycnZsRZ6NBLc5Werq8aKo6LRx7J6FAp89SKnlKg10VgwcsDGe8lYOB6UgaUluT8Mwyk/fQCCra2toz9I2ghEOGlfFQUDD9xzAsLC1OXLvKkXj6fx8nJCQqFAhqNhjFZKysrRn+zz/S4CKQILv1+PyqVio1HZZl75S6gx50T97u6hi54mcUM8TuuUb9OcXB/uDS9Cwxcltdr415Q2SK1T6WrQJhMD/cJ14MMA2WMxS+LxSJWV1ctsZ7zQoPHcLvOJ8etjQmm9IDvAnp48IHfYZ9ZJt8NQSnI1DwNspKJRALr6+t271gmkzFZZuiZYJ1yqX1fXFy0HEXOVb/ft3IiiUTC8tW8AIKLiwuTA7LZfr8fZ2dnePfuHV6/fm3VkQnYWFyP68jyA3R+yVyxSCFwlQ9JHcIwHeWIAIFhFjK9LhsCwPLDvJ60uy6cwme7zJXbFKgRlJJJoX0jk0UHrVwuo1AooFarTYWSFMDT7vD9/LeCEa/tpz/9KTY3N7G1tYXt7W2kUik8fPgQX331Fd69e4f379/jm2++MccxFotNOcwArMApc+d2d3exvLyMdDqNyeTyji5eycSb2bmmZCdV33C/cJ8wEsHik3p45bp2I+BRqlwVKSebE62f4f9RmSi6Ho/HSCaTdglZKpWCz+dDs9m0y/4ODg5Qq9UMMfv9fjv5tLW1hQcPHmB9fR3z8/OGDp89e4ZKpWInpQAYKPLaONFkP/g7NRgEeETNTOaiB6oxU3o0zDuoVqv45S9/afPD7ykYdI2NmwOhGyiZTFoxw9uanjBSdK7hAxoIDU0AMNAZDAanmBE3vMGcAHrUVDha3E3pSgWXrnenRs0LIIjFYnafCwWex1rH47Ed+2SCMRNV9e4ghmBYLbRcLqNarU6FTslKcpPV63XrH+eVG5Ly4o7HpeC9NlfBKkXvzpv+nopV51JBrvtZF3Dq3lZmU5ndm9bKC82snwVgybR6YzT3JOXYremkLKY2DTtWKhXLf6DC1H3hsmc6LnXeUqmUJXW6CcS3NQU8+m4mXruMk7K5uj8ZktOTPQQ81Ck+n88ABI//TiZXoWi9fJQMJ/dLIBAwQMKCsl4ADwE/jR2ZXl4gWa1WsbGxYRd+kuHgmNXrp+dPcMYbuDkPugfUMGruF3W25vW4DL2yv16ayr7LquieA66S4NWxcB06zXHh9R7UwUzc1jsJlcVU1pbv4++1CrH210t7/fq1kQB0CuPxONbW1mxuDw4ODFBrUz3CpHfeYEDHZGlpyQr6rq6uGsPWaDSm9BltjzI/bjX5u0QDbgU8XEwXJarHqEpRlaoqRHaKgGd9fR2JRAKTyWV9mf39fRwcHCCfz1vOCA0YKbGdnR3s7Oxgc3MToVDIUO/Lly8ta5y3Ka+urnpaWBVGNd6zwlWc7EQigXQ6jcePH1t9nmAwaIJQqVSsvD3DLO12G8+fP7dx7ezs2AZlm0W3cvHpCcViMQwGA6RSKc+AR7P83aOiwDSwmpULQgHTkJF6jKTQefeZS7+S4nY3+iwvaFZI8bbGUybKNqpRZJiJSqNQKBgg1iRghk4JeJgYyM2+sLCA5eVlu3JEw2WaFKihHa7rb8LkaHNDHnyuUr6zQI++2w0/uWFcBT9cI+4PlzrX/2eenbZZ+Se3NX1+LBazUytaZ0lBggIe7k2GPLQfZGppQJlgqVfWsP88OaVOjobTeNorl8sZc/KbAB4tBspaNGSr6M3S6eP6uobgOtDDtVIAobl6GkLTAwfcE2SQqG9YSdwLA8LP8nkMgbN2TLPZtMsiaeQJYpgYzSK1DHNsbm5iYWEBqVTK9rfKOe2OAgXqYrK3s+TCBSJeAQ+NsOuEuGEYV79RTtVAc73JpumVNpoHyZOg1L8qn24fuF/pnFOG7wJ43r59C+AyBLuxsWG5Ydls1hx6On+sBaTjZP/7/T7K5TICgYCFsYbD4VTYbnNz08AOb1RQFovRE47DLap5l3Yj4NEy5S49rshSPSsKjypnIsVoNIrd3V08evQIe3t7CIUubyTO5/P4xS9+gcPDQ8sPoSAHg0E7ev75559jd3fXjpVy4Dw5cX5+juPjY2xtbXmuQsyEaU6sZtNz4tmPubk5PHjwAI8fP8ajR4+wu7trn2OfGXpjOfR/+qd/wuHhIc7OznB8fAzgsnDVw4cPsbOzg/X1dRNS3YD6Ew6H8fu///vY3t7Gj370I+zv75uC89JYwp0AgKEjrinHzbWmIeC69ft924ScHwo/2TpWM2Xoq1gs4vDw0MJjKpzu5iQI8/l8li9AhRuNRm8dH+XNrUxarVanDDsrlZbLZWSzWaRSKfOohsPLqyJYLPP09NRi7ysrK1haWrKwAUHReDy2Mu+TydXJok6nY/lNs8JHwN3ydwBYeQMyURqOJABgPpZ6deoNK4BhXzVU6/P5jM0iA6JMBN8LXCVE0mCyL1xH4G4Vevl5DbmR5aEBpfJWvUJwSS+Zpz651gqsq9WqVWqORqOoVCofJYCy+XyXhQ0XFhaQTqeNDQyHw3j06BHS6TQ2NjZwdnZ2p5AWbwinA0D5px5SZc/mgmqdY3XSeCqRxpggfjQamWwwzMP5VtCouX2pVMrCPIFAwDPDU6vVkEqlzPFk7uHp6akV61xbW0M2mzUvn7pFwY6ycVqIj6E/Ml/KcFKHa50tlppgAT9dX90PCnpva3oFjYZ21UFTkMHxsc9sTMRm8VyGF5WBL5VKZtvI8HD9CWi0qdOiTB5LquidXze1g4MDSwlIJpN48uSJ6Xzmj52dnRlQJTMDXB0EovPQarUsHaNYLOLs7AwLCwvY2NjA5uYmAFj4s9PpoFqtWnmJWY4yT93q/YFe6+55y3p1JlMRrIsw1YiqAQ+Hw0in09jc3EQ2m0U8Hrfj5jz2q0WU+D4tMLi8vGwbWidAaXjdPF6aej16GZo7yZlMBtlsFk+ePLFqrTzKqbk9AKwe0OLiIs7Pzy0cxA1cLBZxcnJihZ04Vr4LmL5Ty++/vAdodXV1ZjVfr+vG5+umdEMRLsWv43KNHU9+uWE9eldag0HHqE3frUnMbmjlpqagm2tI4KZHYvV0j+ZAMHehUqnYfVnMXdKLVHmkstFoIBgM4uzszE57aShQASUBhzte9/e3Nddb5LpoKE3ZOzeW7Ya1ZjX+n8qd/k7DmPwdFbs+3w2feV1H4CoPgvtQvd9kMgmfz2fMgOoYMsFM3uUa6dwxtMLPsp6PsmAEuQT1WtWXn2F5Ccq8W1vqpkZAT0et1+uZQaIzwiRTNq6rzg/3qR4j11IIPPWTTCYtL03TEgaDq6sKaDA0yZh5NeFwGK1Wy0DkbW1packq4RPAcF+x2jWBDuebTL6bCsCcKs311KsJyISRyQKuEoUZktPj7276AOeDoXqvp7RUN7thLXfvXLffKNuaD6YMz2RyVR6Ex9E1nMX3agiLssL/53vURnu1GePxZeHY4+Nj5PN55HI5tNttC38uLi4im82iUCggHo9PlRNxc5kmk4mldfDZx8fHlpu1tLSE9fV1dDodHB8fYzKZGHPkhnQpn2qD3FOnNzXPgMelvFX5KZJVha50YyQSwdLSEjY2NuzGdV4y+u7dO0N1LhVOwMP4NG9qV4Oo6J605l2KSAFXgEerP3McgUAAS0tL2Nvbw9OnT00RqlJ3w0RMtiT6PTw8NITOI+bb29tT7BDwcSVeCizHzT+pLL003YSu8GvIUY2o6637fD4TPg3vMSGQSbpkdAh4NE9oVnPDIy7L5QUU6GkEpXGpMHiMki0YDJpxJIDmxZSs8dJsNo1VSSaTFs7K5XIWXnELXwGYAiGqGLmWlFNd47usIZ+lOR66Xqpw3LlTOVCFqft2FmjRPa3yedt37spizcrhCoVCUwXZyLwQhLDR6+TnSqWSgRT2o16v4/T0FP1+H5FIxEKcyq4yhDk/P2/7XBOZfT6f1Q3To9xeHSwCHr//6koIyizvI6JRZ2PYjLS+AmvmDOrlvARs0WjUgBDLfLDmDPvLStMMOTD8QyaA9beoy25ruVzOqujqpbvVatWq4jP3kePgfqXeaLfbVqmXRpFF6thvjpH7zAU8HD/1EueRn+Hn9NSmV4ZHHT831OyCnlmN/6fMHIsNMj2CzBsBD0NatGuqz/lv6gQ3jUT3/G1JvdpHhvTPzs6sPg6B5GQyQTabxcLCgoU9uT6MCLB/tIsarjo+Psba2hpGoxHS6TRWVlYwGAxwcHBgNdC41gzP6SEJjoe/08jMTc1THR7XKM+i7jR5WQcKXBr/hw8f4vHjx9ja2sLc3BzK5TK+/vprvHz50k5lUcHRSAKw+zxY3hqAJc5yM7Owkmt4vDTNV9A7abQfmUwG29vb+Oyzz5DL5Uy41MAwbARcntbhfDx8+BCfffaZVZNkAanDw0N88skn6PV6U0mKGuMFpm/VVRByF7SuFLayIdykjJFqPFuPE/N99KQJQvmjJwQYe9dKoEr5U9HzORyjeq4afvOihFjTAYApc3qj9G57vZ4ds1xaWsLW1ha2trawsLBga/P8+XO8fv0a+/v7ZjDn5uawvLyM1dVVbGxsYH193bxTGoFutzs1pyx6yCRQjltPZs1if7ysIdeDioPhwmAwOFW4URWgepxaf4ZyriHc0Whk9YgIIqlk1YlQYOImQPP/XSfgtqZMGb/HJOGVlRW0220EAgELiSibx3vrAoEAtra27BJgApnRaIRisWi1vng8nEaFazSZTBCLxZDJZLC2toZ0Om1sjIbZKccM53kdIy8R1hyw4XBoN1pzHbg/yHxQxmjMVY4o7wyvkv1imAy4DKMzjElnibJDOQqFQsZWM4k5FLq8OJknMW9rDx48MLB0dnaG169f45tvvoHf78f29jZ+/OMf49NPP7XK9ZPJxA4XUKY7nQ7ev3+PeDyOlZUVY7W1fxrG4o8mtOscaogPuHLemN/HnNHl5WVPa+iyOBo6VtDOXBr+HwGrstEEPLlczsJ8ZPgmkwkajQYuLi5QLBZRqVSm9Axtr5twrY4Ym37ea2PuG+eIOpX6m6H+VCqFcrkM4MppUb3P3ykjd3h4iPX1dSsEmkgksLGxgZ2dHZTLZbsrkmVcgCudovlvbqoNP3ddu9FiqvLSv/NPNzdAk/tUIBmnZIXTVquFcrmMt2/f4uTkxE5NzFoMLjCZDRV29kO9XgUIXhrj0jRAbtLgZDKx/BQaaBfN8/tUemqsmfiXyWSmWDF6Mp1Ox5Sd6yGosdfxucmrtzX3SO8sD39Wc1knDWGR6meeCoWPhQYJQl2gpuunRkI9FWA6b8HL+HjhJzcnKywDVyGBQCCAWCw2FS9nbs/5+TmOjo6sbhIT8RTcMZeE8kBAwHgyj+BSSah3ed0c30bB6hhVJpUBu+5HGUKutdtnyjuViZ4Uouevsk2Z0PDIrKaskNemDKN6q0wSZqiCNLgCNuoOOijM+eC9fWpMmRys+1FZ4ng8blVmmb+jBpXjp/67S9iOxoLgU9kdAiACC/WO+Xs1dhreJmOht3crA8uwM8NwfB7vgPP5fKhUKqZ7mOfE93l1rph8Xa/X8ebNG6vUzmsKNjc37a5DtRMaomq32zg6OsKDBw+m5kgdM64B58mdAwUXLovJ7+oBCz3WfltzwY4+Tx1o/X/3/WSoIpGI5WOS4VE5oC4hA8U503FoniJwlRrA8ete9rqOzN9UcM114ntpE8mmk7mko8e+aUTA5/NNhVPJWtFpUbnjGVqubAAAIABJREFUftQke57Ycg9dqD35PwMendxZgEMXkYLAz/j9fjvGyXBAqVTC6ekp3r17h4uLC0PYfJ4Kh8bqFMGpMdYF0SRLL41HF/kubi5lHdyjky6jpfOgVGm/37cFTCaTUxSo5rowPOaGAzSkpPOuG9xLU89IjeCssIM7t7quWqSPhp9KgsyCxsNVKBXwXOeh6dgB7zdtU1nRM2UVWT3CynmIxWJTVOxweFljhOHVQqFg3orPd5kgx9AGvVJlAulFEzwo4GE45jqwc5eQj0tTKwCeBXRcMKmARy/g1WPQNJIuTeyGJWc5QLPaXcAOm46LRmFhYcFAit9/eUx2YWHBxsB9y/dlMhksLi5iaWkJ5+fnxjTSMyTl7t4oDlwabAIsJrZrfRdNNnbBiJc2Pz9v71Mvn+EserBs+g7Na9LQk55OUmeLc0MWQeeL/Vf9R5aMc+wyBF6MJcPa5+fnePPmDU5OTtBqtfD9738fGxsbWF1dtZotrrwGg5e1z1qtFs7OzoztoO7VnBDVZdSpBHsMX9NuzNJ1ygZ1Oh0LJXlpCnZm6WedL3UoXcDDZGq9P4vJ9JRTZeMI4uicsxFocc8QiLt5LgSjXhrlx51DBTx8rs/nszmnbFIOdY1oV/UUHQEPwTl1Nw/A6I/LUKkcKBi7qd0a0uKA+SJ2VgVVE+E42b1ez44mfvrpp9jZ2UEul0OtVsO7d+/wv//7vzg+PrZ3KIJLpVIWowZgVCxDKpwArSXBHy7KXRLQaByY18GigEobq0c3y0iTTeDiAvjounuOhV4Fx04KU0MAsyg6F9h5HSNDFMq2XOex07BRserpA4KdeDxu3ggNBml13rWldxqpF8S+k5rXfCJl8O7C1KlnQSXG0wxMPA6Hw1NhKV6BUalUUCwWUSgULPSleTuLi4tIp9NWC2YyuToRtLGxgXg8bveEcROXy+UpdpPzTGXlgnovjXOjAMcFILNYPFV4NHw8/cZ9zRotnDs3AXAWkzQrL4t9dEPbXml0Gjw1gHNzc1hdXUUymbR72rR2DBUsxxEKhbC1tWXrz2q9lEnKHh2iyWRiLGUgEMDGxgb29vbw5MkTqzZLEMs8GX6Xzy+Xy6hUKp7GSEXOMBkNG3NauD90/rmHVPcRfPMwCP8NfHw6Th0W6kz+n8oVTxg2m01zQmnQ6Fnf1qrVKvL5PN6/f49vv/0Wo9EIe3t7+KM/+iOsrq5aDhP7qQaRuUasau/3+6eYZMoH122WjNHpIoOpRUVVDzEUyJIAnMu7NJdlV93l9pG2Q0NaoVDISqgouGY9sGaziVqtZpd08vuqB9SBJItN3UkWkHNIp8ZL4z7m3qLcaRhJ53R+ft5uWE+n03ZX4cHBwZStURZMnQXOJRPt6bTwswp4tD/KAGnfr2uecniUsXEZAipUPRZG5ZNIJCwDm3kWhULBrkggYg0EAkilUoZ019bWbNPRwGu5c50wXUAXIHhpanyoZJl/QWpR7zBJpVIG7kg5u8m94/HYQCHHwaQuKjI3rsy+EDgwJKK1ZXRsd6HROVcuSHU3ixpRrrHeSsw+u1nx+gw9uqxC6oY/lIVwwz6TyVUM2Avg4We73a4d/8/n85Ykx1yA9fV1S5qnt1Or1dDr9eDzXZ7E8/v9ljNGkK7sAWWWAIpeM49dskaPhinZOKcucPbSXDmZ9cPPqderYVrKkx7l5Oc4LpeVuS585nrobC7VP+uZ1zXNZSPbREaKoRl6lmrE1OAxHLO0tIRarYZsNjtFx1M36XMAGBgkC7G0tGSypbqHSpt/MsGWrOBtjeyKKmtdD64T+0dniDLHfvICTZ7ycRP2NcSi4JSMD+cbgL1H54kOJ8NouqY3NebvNRoNC1HwAkpezqv7nflmACzBuVwuW2XlTCYzlYfjypfaImW5yGRdd3JHnT86AJqcflPjaSqCQJfBHo/HU8fHmezLlAgy4Lu7u9je3sbe3p45YN1uF6VSCScnJzg+PjZHjI4I97KGaambuU5cV9ovALZ3VAff1HTOVN+7Din7QYfkwYMHyOVytpbj8Ri1Ws3y5Ph91wlmv9VG0r6639H+zKrJc5NOvTWkNetHFYx6VnwZve1EIoFcLofV1VXE43GMRiMDPPSIONBUKoWNjQ1sbGxgd3fXivednJxgPB5b0SUtCqibmX1yDcBtTZkUAh7GEJkczcJPPCqpm0xPT+iCUhjq9bpduMbFJJ2pyJSKhlVGa7UaMpmM3RemKPkuQIffcdfTNVpqvBTUUoEC04KmeUTq9VPJUgY4Li3SpxSkCwj4PDcufVPTCsmnp6c4OTnByckJ6vU6/P7LI/1ra2vY3Nw0wKMJiwxJraysYGFhAZPJxJQ0w7AKeIBLA7m8vGzrScBD75KKSBv/rRT7XVge4OPTkrqO+nwNYalTovkQbh4L++MqI5fZcVkmF3Dpn+7fb2oaPuO/Nd+IibPKdPL5XIdAIGCnOlutFlZWVkz+3JvUNdzAwpLb29tYX1+3a1sIpHU+OAfMRaBy9zpGZbAU6CgbRzaDxotrxSP6PLFKMMhxcb9qP2cdGuD+BDAlCwp6XMbXyzqyQnm73bYyJA8fPsTi4qLpZwUoZPEnk4kBx4uLi6kkXk3CpXyqI+TqDS01MsvzV5ZZAY+Xml8A7E4vzSfhWingoR5kXS4CEubjrKysYGtrCzs7O3aMv91u2w3xHz58QLFYRKPRMNZPDxJw3ynjwTUGrgAPWUxl/W5rqt9nnV6eTKbv1lpcXMT6+jr29vawublpdqzVauHo6MiYUa6Ba/sUvOi6qmOsoF2ZHjfEeBMwvxHw0KCzCiJBhypIdoSdobGnV727u4tcLmcCzRvEW63WVOJnMpnE6uoq9vb2sL29bbkPb968MfDDO5yYewHAYtnM8ZkVr72pUSC4GSORiBUbY4iiVCrh6OjISmuzvgPfwclXZc3FKhaLVmyJijMcDptSjcVixgg1m038x3/8B16/fo2joyN89dVX+M53voNPPvlkapE1QdNLYyzV9Sbd9VOFoMCVxlNvWVYKmUfvyZbMAjwaO1alClwxQcoWkbXxQsGyMjKLBlar1amTUyxhns1msbq6itXVVbsclGXTl5aWsLm5aWNnTJ3Gk140cJXLQdZPK40SMNMYKaDWOVaA7KUpSKWidoEqn6shEA1r6dorc6de1XWgh2vo/lDhqTKlQXIZPC/NdQo0/4QnqqhjyMwp26NMHfdWNpvF4eHhFL1OcEVjkMvlsL6+jj/4gz8whkeNLOn8wWBg9/Z1Op2pUgZeGvedGhIFo7xXi7pE8xcYZmVNMNV7mpukLI8bGg4Gg0gkElPsGH/cFAE3zOxFVr/99ltjN7766itsbW1hbW3N/l9DYxoq6/f7dklzoVDAw4cPrcIydZB+z03W1h86agxnuYmuZOYIPHhtRSKR8LSGWqHbJQAIhLVkAK/nmUwmxv5OJhM7CMEK17y/kCH2Uqlk4SzqMjXw1CtkLoEroKIsKHC3qAcAc/p5y0EymbRQMsEObfJ4PMajR4/w2Wef4enTp9ja2sJwOESz2USv10O73caHDx8sVycajVrl7Hg8PuV4kP3S5HvNNaM880dJD90r17VbAQ8ny8390MmelU/AZKylpSUrTNTv962Annqgc3NzhhDX1tawtLRkpwcYx6TXwM2qNSwIVihogHclq+NRiplonCwEF07Dago41BvWBVSattvtmiAyaZYbmffVvHnzBvv7+zg5OTFBY9E7NWZ6XO+2xjFoSEO9e5dt0Mx8pf71tIfmC3CNKpWK5QoBV6cFNLuea+OCUw19UIbUM72pcV0oF7FYDOl02pQeK/ASxGgdlUgkYkcueTHfeDy2qw2Y/0PjROOihkCZKA35zcp7cENTXtssAO9+X72hWUzLLBbmJsfgJmU5K8Q1K/R1l6a6xA1XKYvKNhhc3unGNVMgwWtOVldX4fNd5f3M6hNLFWSzWWxsbFi1ZoIG9kfngoaTRs1LjRrO6awf7kWXPQWumC6e5mGuBPNayCho3prKp+YRqs51Q0X6f9StGoL10nhvXTwex+bmJnK5HNLpNJrNpn2Ge5X7nnpb8+80ydrVC65d4jNpHF09p7aKwF2Buvs5L01ZRg1pERSrzVQHhGCSyfEaGlPWudPpWI4XZZZRFMq7hrXYD2XD1GnUkhVeG/PDeOEnLzTlM8vlsoXbeJCFicnA9CEg9ofyrYc+KMNk6XnwBZg+gaeso643ZUFPMF7XPAEefaGrMBT9qyCymBINOz1CUps8FqwJyFtbW+ZdsYZGu922UuONRsNOD7hCDUzXc/Gaca9KmotDGl0VLU/e9Pt9835ccKXeIxE3qb1isThV2ySTyUyVVWd9nnw+b7Hbt2/f2r1jejM6x+/VYHIMs/I3VOlyDC51yfeR3SH65/zU63VUq1VcXFxMxY0VyDBvgmzadUKpMsS+39aY0E7vIZFIYDweT+U4sPorj6vzNuhoNGp3uIRCIfMs3JMtbgKnG4okE6Vjdo3krDCW1zW87ns3ARv9u8vg6e9cRa+g5abm0s3XgR2vzseshEgFxG5/6E0zWV3ZGJZPyGazZoBTqdSUPPEdTMJfWFhALpebOharCaDAdG0y19v00lyg48qLq7A5Hsor8xx5zQL1EI0cL/6kN6wgUp/FatU0EjrP/AzBkOb73dZ8Pp958Kurq6bn9VoKygeZGjXeNNKacMx9p441bRL3nxp3BWya5sDPKUNJ9oXy5KXNYkEV8KgcU59qsjnlcWFhwQAPgQsrTWuCvDpTyriyz5w73dcEknpyzWtdMz4jEolYPiNzxngartPpoFgsGqtPsDOZTAzcus6vOia0sWTCNR+Oh0A4Zl17BT3cf67TfBNwvRXwEKVRAJXmBa5qoGghKb/fb7Uystmsle9nIhoXSE8mBAIBoxbJEAGwe7ImkwlevHhhE5hKpQwx85hqu922jHSv7Affw7EyU/7JkydoNpsoFAoWhz0/P0exWJwK9fC7Gp/k7/v9Pvb393F8fGxXFTApe21tDbFY7COGjEpoMpng9evXAC7vp2FuAunuu3jQFH5uPhoDGnSGKoErA85nc81jsZhd7UFPk6fNeNdLpVKZMvzuaQxNLOXvKcyzAIPO5U1N68kwOV4TU+mpUCYYClGwQgaPipNKkPJPkEQ2jsaQHikvaWRJdIJj0tU6Nr77Lh6lev/84ZwqI6DPpyJWYE4PXEPAfr9/yhPUcJmGz5jo7Sav0+vjs1xq2auc0jDofLlOBKu60siz7/w3QSu9YzJ02WwWn3zyyUdhRbKCGj5j35U1BKbD3/zhje5erl3gOLg2nCt37bQRpDBpW8tBMGShc6/GVUMA/D0rSPOQiBvapm5nyHM0GlmJfy/G8unTp1heXrbSDwRkiUTCGAYaOD6v2+2iVquZbue+ZTkPl+HhPKnR06sN9K4lPQrt7lcCHobjh8PhVPjtuqYsDZk0ZRrUudQrbBYWFrCysmLgenNz03Jb6fTylCj1llv2Q+cBwNT+VvnidzqdDiqVipEOXk/2zs3NYWVlBU+ePMH29jYymQxCoRCazSYODw+xv7+Pr7/+Gufn5wZmeT3Py5cvjaR49+4dyuWy6U7aWdp6pgq022271kdzljR1QpkyTfrX08Rci+vsxo2AR6lQnehZBsrNiGc4gFU/ubGIAoEro0Slxs/2ej2Lyfn9V5nr7969m9rwTOLb2tpCKBRCNpu1nCGv8Vjei6Mgrt/vG9PEarosd31ycoJoNIpMJmPXEjB/hz9+v98uD33//j0KhYLlH2UyGWxtbU2VV6eApVIprK2t2V1b7XYb+Xwek8nE/o9HZe9iMGkAWYGU66Asj2v8+T1+lscbU6mUAS8qjlarNVWuHrgCWS4DqMyICzrYNz2N4AXwRCIRM3D0TilTNBQamiIzRSWoSopj1pi8e/kpDSq9Md5ozB/OU71eN2bOZVc4dq9NlZzL9qixJMihZ6cMzGg0miq0qcaWuVg0AgR+bn+VgdF54poriHLzi7ysowuGXbZDwYaexFE50ti/Gn+VJwVhCtyUhdPxKAhURzCVSqHZbHr2nDkOztes9ZzFlt0UvuS/+SzqYwUw7LMyPDzWr+/kc3RO9a6u29rW1pblvgGY2tfcY9pPN8+LTqw7FzoWbdRXjUbD9BYdIM2rVF1EsMVn6oXVXpresUZQ5SbSxmIxcw6Z05pOp7G0tGSsCWtJUQcRsOlazc3NTUUtdH+o7dSaTspA0ynlNRFeAc/Tp0/xySefYGdnx0iA8XiMSqVi10EVi0U7CUtnkY7uxcUFPnz4gLdv31qolQV4V1ZW7Bg+r6nodDqo1Wp2/ZKyYwT1tA2a2K/yrftBT41ru/VYuio3YJoB0IVhJ7hRWK+FIIb/p6es+A4+T2OZXOBgMIh2u412u23lxlm5mYDn4cOHWFhYsFMZBBNeGkvHq+IeDAZWjZdX2jPBLZ/PY2lpCcPh0MIjBHEcS71eR6PRwNHREQ4ODlAsFtHpdKy2wPb2NpaWlmyxGX9kee2joyOEw2HUajWUSiU74bW7u4udnR1sb29/dFz9pkZh0DpJBKGz4v1MflRDwBo8PCVCWWDxKNKXnEc3t8OlgalclA7WvrkJ2jc1XrzoerL0zpl3pCdYqCh5/xA9d5c+1tM97B8rnxLwsGooQ2O8XiOTyUxtRpdy1nm4rd0EHFxWjMZXY9wcC8v4k/rXeD9ZKQ0PzAJos4CXhn8VRKv3e1vTPUsDpXpHx0rAoYaTgIdrSp1C/cS8HM6NzqmGdzVMyL+7gIfGO5lMejYi7prpO1wdy/HwZKoyCOwH9407N244kI3zRiaL4RVg2oByD+h8ug7NdW1jY8NAAA8wAFc3aNMRYn/d/UbA4xp3N/yqDAcPTfC5bv6R2ivXYQ8EAmg2m551DXB5LF0LkarjSHljaJ3HzXlB6OLi4lRRS2WglPXis8j205lzw+nKgDJPTXUoGbpWq2Xr6KV973vfw/b2Nrb/3wNEDEmVy2UcHx/j4ODACiQGg0GrYUa7wZBXPp83tmphYcHy5LTuENl1Ah7VyVwjl1hxD94A8OR03GgxqVRYkI9Z1brJmITcbrexu7trybnLy8sW1iLoceNxSpeztgBZg8nk8vQEE97q9TpevHhhyb0AsLq6iuXlZTx69MieFQpdVhUmar+t8coKChhBQSaTwebmJvb29lAqlUz5v3nzxoR8eXnZWCwKVqPRwC9+8Qt88803ePbsGY6PjwFcAqunT5/i+9//Pr7//e9bTQrOAzf7F198YdTmf/3Xf5kwfPPNN9jf358CeMlkEn/yJ39y6xhdD0GNFHOKVOEqpZpOp6eK7+kN0ewbEwCBj4/Nz/LSb2rKImhuzE3t8PDQvBheQss8APaFlDW9cc4xE+R4QzPfTYMQjUbR7XanKGwmaddqNSuPrrcaswhXo9GYAjdq5PinV5bOBTyzWAD3//hDBQJcKgWXJaVXppVdOYeqeFxKmXuWOQiaeMsxu5T7TU2TDvXkl8oAganWjWE4wAU7wLTh0NM6ZJG5PmRmFZzTuPh8vimWw+/32/wx/JPJZDyNkX1TT54MKk+i8NJbGgDqJLKHBIMavmJ/da4IYnnCVo0p9zfZFMqJzp8LcL209fX1KQaUckK9TOCkITjOC8OlrN/Gk0HKNhG4zNo7fCbD9Zo3yHWmPDBU5PP57KqL61gBt1H36gW2mixOR3xhYQHD4RALCwuIRCJ2cpmXEPO7w+Hl6cN6vW6XvFKuGPKhTmJzIyWUIzcxn/aSdXi8Oh9//Md/bHcPArDyKt9++y2ePXuGN2/eTOXSPHv2zErLPHnyxOwKcyPj8Tj29vbsepG9vT0Lc56fnyOfz2N/f9+iIUq0EKAS4BBo6n7Webip3Qh4WFafyXw0fFQCBCUs9MXTV41Gw1A6hcFNfOMG479p9Km0uPHUK6/Vajg5OcFkcpmgurW1hQcPHiCdTtszx+OxMSw//OEPb11YN5RFYWGuzd7eHg4ODlCv1636ZT6ft5wkJp7xaHSpVMLbt29xcHBgN76ybsann35q7I4qa/1JJBJ48OABms0mTk5OcH5+bkacin08Hhv48Nq42Skg9MapKJW+pzLkSTs9PklWgIlwenxQlYs7t/w3++I2NeDaRy8b9NWrV8aylEolkzW9BqJUKhloUZqXeTccC43I4uIiMpmMHYtlH30+n8mma7BmXdnA77lzcNemTAC9HAUZ7jyrJ8wwj4a3+KMJrjToymbM6oMb9pmVe6JOjVfAo2utgFeT4DmXVHbMX1HmZRabOB6Pp66WaLVa9izKNI2IepacH36PfdH8G3r0XhqNjrtPdB0VfLZaLduTPLlDMKqATPc330HPnkewKb8qj2ogOJfaP93TXoAPP8N54bqSHdL38zOUHYYtGHIjIHfHpWymziefSbCjcqFOnobNfD6fnej0yvCQPZ5MJnahLVlSOoA02NQD6jDxu/V63Qw3AYXe2k69QsDHqvbuvqQeIJDjnmESdLPZRCKRmGKEbmt0yOnUlkolFAoFvHjxAsfHx1YegrqCuvfk5MQq1H/nO9+ZAiPb29tYXl7G4uIigsGgAePT01Pk83nk83kjTNTh0D2tUQfOi6vLbkqD8AR4lpeXLeZIxEchCwavLkBbWloywSadpmX+3cQ3UsEUfP2M3s5KYW21WigUCpYzUqlUUK/XsbGxYZuLpf29FgIDrgyAUtMsVtfv9/HmzRvk83ljoJhfw5tiI5EITk9PcXZ2hkKhYN5/o9EAcHnsdWVlBY8fP8bGxgbS6fTUBlZAyGqvfr8f+/v78Pv9Biq0vsNdKFg2RctK6bpGgmEgnl4hhcvrCICrKzL06KQLTvS5s4CPzr0LivlvLxv01atXptyLxaIpOYaxmH9Ew8Z4Ma8c0NMLHDur6wKYug+L7AM3GJ/PI/uMVetls2rYftPGtaEidQGPG4pRY69JnS74UvCkjOsslm5WuMddWwIlKmY94XRbU2Dk5uPMAlqUf5cF5DyxP9RDDH/w+CvHoSdFOGcKrKibNKFdw0M8Jeal6X6nbLshLfaXp2FoyBhGJehRg6COAtdaQ63tdhs+n89CKBo+VrnSMJIC31kA+Lo1JLBi/gnHQ2CgY1Y2kOvMqAKBBUESdabbRxeEakL3LJlhXh/HvLS0NBO0X9fINPBkEfsSDAbNNmmflInjGrHKuwIeHnbQfBXWnxqPxwaqub/UqeHnyRRy7xE0660FXhrBTq/XQ7lcRj6fx+HhIV6+fGl5NirLvD/t8PAQm5ubFr5LJBJGbPAEJFkoAnFWxs/n87i4uJhi/zREy3+76TMa7lS9MKvdmgRCpQ5cFgUqlUo4OzszT3B+ft5qzbAacaVSwZs3byxrO51Om4HkJhoOhwYIuIiK1guFAk5OTrC/v49ms2ngajAYoFqtolAo4Pnz54hGowZ4fL6re7R6vR7+6q/+6taFdTeMUuHMqO/1evjlL3+Jb7/9FoVCAYPBAJVKBf/yL/9iQItUJE+GDIdDi1t+97vfxRdffIHPP/8c6XTaNot7hBG4BIF6nP/Vq1d4+fIl/ud//sdKdDME6JWCJSPDpFX+qEevc8CTBfwh6NE6EAzhEDRwHKoUrzOSSi+7m5ftLnT6s2fPrC/VatXeTU+PgIebgSeqms3mlJFl0iwLwLGK7vn5OQaDgc0H72xjiQS/349arWZFxbLZrJ1SYXNDe3dtbn0Lyp1ufp07ypQLqgnqZ+VWqBy4ykMNjoIRl+lT5pJ5Ql69SgJnhnX09KDG7FWGqOhV4XEcg8HAbksnmHMBj99/WYlbQ1QK4vRElIZG+Bl1HLyOUU/EaQFHnUcFHHS06vW6hWuSySS63a6Baj1pyOdQJ7daLSv6Fg6Hp2rQuKy7hhG5tlwHLzk8Z2dnZjOYkKuhLM6Va6w5f8xljMfjBgZmha/I2DHUCFxdD8IwGJ/Pd+oa0XHns70COr5bj1wre8N10AuU6VCwEjvlqVqtGmBmeJ3shuZoan4i9ztBEXC1hzWkzB+G8ckUem0//elP0W63jUAolUpW2JX90ZzQYDCIs7MzA9dPnjzB48eP8cknn9icKQt2eHiIi4sLXFxc4PDw0AoSd7tdA7rKSGvUQcsNUHY4J9Q9DFm67dak5VarhYuLC7vZ/PXr14YgiWqZuJnP51GtVtFqtfDhwwfU63V8+PBhSvBVAXc6nSnPBLgykoxp6i2sHCSVaafTwWg0wunp6VSY7S7Cq6yOHqWlYpufn8eDBw/Q6/UQDAbx61//2pQI+z8ej+3vwOUm4imux48f208sFjPwwflV75/vpDfAyxJ5L9Pp6alVqb7LGNUjUsM1K1GOzAhzWKhAKEBUXsxbocepY1eQojkR/FFFq8yJGhKupxevq1KpGIBxx8w+qGceCoVm3o6sxbD4J8N6qoTZN036DYUu745j3pmGG9VDZfO6dmzqhWv4cRaFq8BE36NGRr13/f51c677SlkEzW1Rg0YZvstYFajxmQwzcu/r55T2pnzyuwQ1PElCY0LAo84Ww8NaQp/PZB4DS2vQIXATSL02BaKqCzVn6f9p72x2ouiCMFwDUWEBGAcTYwzsvAJde/1uuAFdaAgMwZEZ4kAMQedbmOfwdNlAD99KUm9CVJyfPqfrVL31Vp3TvMZKXlZs5vN5I/QR0QiJS7Sz2awp5QSB5XLZabZ3KYd7afLFnA1tWnZC6525JFjX19ctIfR6QJ2gv8xn6eQMnn+TrKEiotx4nm/L/N3f5yM5hsBxAkXLh2BC/H09Turoq6GqQE8kJMk+FBtnfJAzr/389HmUIX/nz58/O0TzPnz8+LHZwo8fP9qBiD5l2qo8pyovFotWrjo/P4/9/f1G3p4+fdoUp8+fP8d0Om3VGJJm4gPJRFboXMZlXp2wcb8fTHhQdRyk85kTBE0yBxSAyWTSbloOtl7s/B2+o32aAAAHKElEQVRHYyO3vGfpls+8urqK+XzemZRV5EkaxJjMHADW19fj1atXMRr9aZa6uLiIo6OjjvzP3MC+eQTFmzdv4v3797G3txevX79uDqAv4HthsjjH43FsbGy03T5fvnyJw8PDODs7a05oCG4rJ3nuGSsOHcKTG8TINpEjWQR8Nq9jTPxpImnmnonOQ+4jC/LqqvvQQO9C87zSI8CYgckm0itP7/UDA/vGxPcSHN0UCUx6hjYP+tqyo3N/QiZVJg+83/0DmYB53p31+rVes1Z2rEwwp0PLkYaJjBUQH7LJ+nEPFT7D18e5Hl+/fo3pdNoOLoWgQwIiohF6b+vNmzXG43F7DVlm306RoePsU8ysuvh+REQrn5AIclwGc0PANLHjSds0Q5PY+CgF5m80GrX3QXxMEPn9feDemfRgq9gJJQ3bKkEa0sPc4k9ysoAv8vliqLm2pb65jIhmL8SYoWQn4oYs4fsZK4SHmIVSwWNu+H7vXuN3kEErNy5VRUSn7YN5teJD7xcJh30ehGcoQT84OGjzwoOvI7onWhPHITx8Hwr66elpTCaT5kc5gJInCnz79i2+f//emthR85jXvGPNhAdbs6LF9d6lZN1JeMbjcWtGmkwmbdBubLQjffbsWTNCanw2Oi6ODm6Y3+/fvztbf51JZKfuRkIWAjf4oX0tfA/nreAc7FjZMv7hw4eYzWbtqcDMBR3ydKPTnPXixYtOtm2Vw8w018whgBF/ZHWeNvz27dtOg+lQoGoQmDgx2s22GBRlLBQeFhqKDrvmrNBhaDmIRnR7WOxgfY8t82fl6z54q7yzfp8s7fMpKGPQ14PzstPBIS4Wizg5OYnZbNayaZwOJcbFYtFRKN3Tw/jt3FcZG7Bdcz9cfvIa8Jr0urMDdPMfpRwchR1GXwmGIIh6wJZXMls+382kQ8C1kR2zBm2n2L43POBTrA7N5/M4Pj6Og4ODODk5iel02unXst16biA1lIo4pO/ly5dNfdja2mqvYZfnaDSKd+/eDb6PDsQuJdlP5LIQT5+GkLjUxn2xwnN+ft7p9yHwcIzDxcVFbG9vt/F7dx5zDHEaekqvD5NFqeczWJvYG2RjfX29nczPyb2Qaq4d4CvclxURrdxBv51jj/uEsHPsBT+7SpLMmTS2bwd/7h126WSF13qDTES0sRAXrOD3iQI+Rw178Ris1DoRGRof5/N55/X2X32KGaQV0jKdTuPs7Cw+ffrUrgsCGBFtLXoL+nK5bI9fwrbhEihcfI/VWHYCDhnjnYSH/hUm370DTLQnwF3oVmN8A5xFYzgR3QdIunPfJMGkxioBv/dnDDVeL+Jfv262Frphkj/X1tbagtrc3GzNbqg6bPPc3d1ti88NjQ5Q/gH+d86os/ybyzH3gc/2CaAQTpMQSAuKHX0u9LUQ7NjOTdMyDuw2dm3nnufAqgJ2ExGdRX8Xnj9//lewh/CwGHxM/draWlNw7LzIhr0ThuDhkin3xxmxn5Pmg7GMh5KdiG6g9Brzj7cA5/XCfGay49Ih1+fga+JvJcLk0P/PveTeWUG8D7YJkqLlctmZU16X1SfPMeVujgmgt4vSKz7LKoszWJ8mzbwtl8uOwsNc0y8yNJA4QPWpf31lGKtALslxJEBENPUEgpGVGWwCEkIvScSN7/WmCPcXcbL1kATLPhjSQl8HSYCzdK8nEi+ILWPyOnJ/Ecmo7T6XPg3bTET3OU3Y/RDgIzOx8veZRLHGIGmObcwVBN7rm9cAkxn36dgH5PcwD7fNyW3wWra4wOebmEfc3HfuFUmFP8NxgvFy/bmPFMXP6o3JjW3IpbxMxDLujJpbW1ud3QyQFFQZZEX+nwADA3PJJgd4WCrwFkQfTugA4e2+VhN4X5bxhsCEh0XEoiHoQ/ooXRAwnzy5eaDmeDzuME7my47Lu0DyfPA6k7Vc9iO7YY6HNi0bOOl8YJYXEZIiB3oRzJ3d0wNAGTMvtrywsvrjMfeNfZUFurOz04hcVglYGChV2IiPh7dEi1Oy7Ox+DzsCbARVysTbuwjymB6CTHg8Z32qTZ8ayn3g/zxXwDYH0c5lFzfbZ3WS7+B9Q0kr4NoIgA5oXtfOqJkTlyhQO3z8AOUC5sVlD1+rSxS2SeYYX5UzzVXG6LXvNWMb8ZqwrUGwsbmIG8JjkmPybrJLSc/jcP+JiQ8/LjHcBc8Lzc6cVYXfcTLgM4X8CCOP1Y9n4d7gqyPiryBIacNrz/Ob4xJxbBU7tQrjtWB/76oEduayIPcPNTTbB0SgzyZynOP9kAze489dxf8wF05C7ZPxB7zGMdjJUVaDWGuOY0647MtsK5eXlx3/Zg7A3HtX320Y/R8nXCgUCoVCofAv4OH7ZAuFQqFQKBT+ERThKRQKhUKh8OhRhKdQKBQKhcKjRxGeQqFQKBQKjx5FeAqFQqFQKDx6FOEpFAqFQqHw6PEfyja0hLHzVaoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:[2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "#visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(10):\n",
    "  plt.subplot(1,10,i+1)\n",
    "  plt.imshow(X_train[i].reshape(32,32),cmap='gray')\n",
    "  plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image:%s' %(y_train1[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqbUg8ChRSxB"
   },
   "source": [
    "**4.Implement and apply a deep neural network classifier including (feedforward neural network, RELU, activations)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fd4FYZBlo9sy"
   },
   "source": [
    "**a. Creating a model\n",
    "Keras model object can be created from Scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQBLz4p5A6SF"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KIaKiIbA_Ks"
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uo3Y-_AlBBir"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wmVCI-qBEW8"
   },
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y])\n",
    "        loss = cross_entropy[0] / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMIH8ep2Bpbx"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class NN():\n",
    "    def __init__(self, lossfunc=CrossEntropy()):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        nextgrad = self.loss_func.backward(out,y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        return np.argmax(X, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZuS8_96BtR7"
   },
   "outputs": [],
   "source": [
    "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DOSGWlBBw-p"
   },
   "outputs": [],
   "source": [
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "        \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyFiuqGmB0Gp"
   },
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        # accuracy of model at end of epoch after all mini batch updates\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        y_train_pred = np.array([], dtype=\"int64\")\n",
    "        y_val_pred = np.array([], dtype=\"int64\")\n",
    "        y_train1 = []\n",
    "        y_vall = []\n",
    "        for i in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[i:i + minibatch_size, : ]\n",
    "            y_tr = y_train[i:i + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for i in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[i:i + minibatch_size, : ]\n",
    "            y_va = y_val[i:i + minibatch_size,]\n",
    "            y_vall = np.append(y_vall, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
    "\n",
    "        mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCTTgOcyB3et"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xI0Z8CJgB6gw",
    "outputId": "b4965158-7d4c-44e5-ea67-f35d210f4d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.01148666903400712 | Training Accuracy = 0.09866666666666667 | Val Loss = 0.011479538557069853 | Val Accuracy = 0.09822222222222222\n",
      "Loss = 0.011154213101038911 | Training Accuracy = 0.1260238095238095 | Val Loss = 0.012139282878346995 | Val Accuracy = 0.129\n",
      "Loss = 0.011048650384625651 | Training Accuracy = 0.13116666666666665 | Val Loss = 0.012319981857825978 | Val Accuracy = 0.12694444444444444\n",
      "Loss = 0.010602341995352335 | Training Accuracy = 0.16352380952380952 | Val Loss = 0.011509493435069046 | Val Accuracy = 0.1615\n",
      "Loss = 0.010098871986259587 | Training Accuracy = 0.16897619047619047 | Val Loss = 0.011454795518487522 | Val Accuracy = 0.16983333333333334\n",
      "Loss = 0.010076455446187732 | Training Accuracy = 0.19064285714285714 | Val Loss = 0.011291108355264057 | Val Accuracy = 0.18544444444444444\n",
      "Loss = 0.01004755272962874 | Training Accuracy = 0.19230952380952382 | Val Loss = 0.011296408072559612 | Val Accuracy = 0.19066666666666668\n",
      "Loss = 0.01025994995060695 | Training Accuracy = 0.1702857142857143 | Val Loss = 0.011420890928340198 | Val Accuracy = 0.17172222222222222\n",
      "Loss = 0.010122358639071436 | Training Accuracy = 0.16840476190476192 | Val Loss = 0.011364682954846933 | Val Accuracy = 0.17127777777777778\n",
      "Loss = 0.010023867756305477 | Training Accuracy = 0.1901904761904762 | Val Loss = 0.011199213621424642 | Val Accuracy = 0.19055555555555556\n",
      "Loss = 0.01005576933948451 | Training Accuracy = 0.19071428571428573 | Val Loss = 0.011207169490642592 | Val Accuracy = 0.18816666666666668\n",
      "Loss = 0.01006788412942402 | Training Accuracy = 0.1879047619047619 | Val Loss = 0.011240663107185495 | Val Accuracy = 0.18705555555555556\n",
      "Loss = 0.01005809889549681 | Training Accuracy = 0.20376190476190476 | Val Loss = 0.01117328448252688 | Val Accuracy = 0.2006111111111111\n",
      "Loss = 0.00949505529372247 | Training Accuracy = 0.23304761904761906 | Val Loss = 0.01092299160613053 | Val Accuracy = 0.23416666666666666\n",
      "Loss = 0.009179865997259687 | Training Accuracy = 0.2398095238095238 | Val Loss = 0.010851620225566629 | Val Accuracy = 0.23944444444444443\n",
      "Loss = 0.009037243473329166 | Training Accuracy = 0.25188095238095237 | Val Loss = 0.010856836534253868 | Val Accuracy = 0.25127777777777777\n",
      "Loss = 0.008985559929466537 | Training Accuracy = 0.26102380952380955 | Val Loss = 0.010875962782527691 | Val Accuracy = 0.25916666666666666\n",
      "Loss = 0.008985216471931888 | Training Accuracy = 0.25997619047619047 | Val Loss = 0.010944042403668426 | Val Accuracy = 0.25972222222222224\n",
      "Loss = 0.00917808243856752 | Training Accuracy = 0.2674047619047619 | Val Loss = 0.011000551914603134 | Val Accuracy = 0.2653888888888889\n",
      "Loss = 0.009096382154536667 | Training Accuracy = 0.26304761904761903 | Val Loss = 0.011076886868049855 | Val Accuracy = 0.2628333333333333\n",
      "Loss = 0.009143397202394835 | Training Accuracy = 0.26142857142857145 | Val Loss = 0.011054936505612706 | Val Accuracy = 0.2601111111111111\n",
      "Loss = 0.009110463938343414 | Training Accuracy = 0.2621904761904762 | Val Loss = 0.011044981293772205 | Val Accuracy = 0.2592777777777778\n",
      "Loss = 0.009089171709097024 | Training Accuracy = 0.27295238095238095 | Val Loss = 0.011048536159232599 | Val Accuracy = 0.2722777777777778\n",
      "Loss = 0.009115844569581116 | Training Accuracy = 0.2693809523809524 | Val Loss = 0.011090840995182849 | Val Accuracy = 0.26566666666666666\n",
      "Loss = 0.009076945333005645 | Training Accuracy = 0.2705 | Val Loss = 0.011087860850147783 | Val Accuracy = 0.26844444444444443\n",
      "Loss = 0.009143030685102452 | Training Accuracy = 0.26966666666666667 | Val Loss = 0.011066429400913506 | Val Accuracy = 0.2667777777777778\n",
      "Loss = 0.009220382965113443 | Training Accuracy = 0.2716190476190476 | Val Loss = 0.011050107925573906 | Val Accuracy = 0.26666666666666666\n",
      "Loss = 0.009122142990256047 | Training Accuracy = 0.2705714285714286 | Val Loss = 0.011044035297351538 | Val Accuracy = 0.26572222222222225\n",
      "Loss = 0.009114495127379081 | Training Accuracy = 0.27235714285714285 | Val Loss = 0.011013611518602466 | Val Accuracy = 0.26661111111111113\n",
      "Loss = 0.009119582571152427 | Training Accuracy = 0.27440476190476193 | Val Loss = 0.011058280623648309 | Val Accuracy = 0.2705\n",
      "Loss = 0.009097721725304932 | Training Accuracy = 0.2771190476190476 | Val Loss = 0.01105970786659729 | Val Accuracy = 0.2723888888888889\n",
      "Loss = 0.00905952783220526 | Training Accuracy = 0.2760238095238095 | Val Loss = 0.01102479365386746 | Val Accuracy = 0.2723333333333333\n",
      "Loss = 0.009103435392141252 | Training Accuracy = 0.27535714285714286 | Val Loss = 0.011011842555769681 | Val Accuracy = 0.27105555555555555\n",
      "Loss = 0.009065715991065718 | Training Accuracy = 0.277 | Val Loss = 0.011008932464540183 | Val Accuracy = 0.2743888888888889\n",
      "Loss = 0.009040956744969048 | Training Accuracy = 0.2805714285714286 | Val Loss = 0.011003681359792574 | Val Accuracy = 0.27544444444444444\n",
      "Loss = 0.009062494901365585 | Training Accuracy = 0.27823809523809523 | Val Loss = 0.011017873146989522 | Val Accuracy = 0.271\n",
      "Loss = 0.009181068105724237 | Training Accuracy = 0.2744285714285714 | Val Loss = 0.010996058105224506 | Val Accuracy = 0.2687777777777778\n",
      "Loss = 0.009184619375578223 | Training Accuracy = 0.26826190476190476 | Val Loss = 0.010952820864015498 | Val Accuracy = 0.2645\n",
      "Loss = 0.00915380560813479 | Training Accuracy = 0.27376190476190476 | Val Loss = 0.011003771902714725 | Val Accuracy = 0.26844444444444443\n",
      "Loss = 0.009228617763834853 | Training Accuracy = 0.27404761904761904 | Val Loss = 0.010940834199171889 | Val Accuracy = 0.26811111111111113\n",
      "Loss = 0.009221647476243652 | Training Accuracy = 0.2673333333333333 | Val Loss = 0.011000454340716727 | Val Accuracy = 0.2625\n",
      "Loss = 0.009175629821181645 | Training Accuracy = 0.2680952380952381 | Val Loss = 0.010956139942087882 | Val Accuracy = 0.2627777777777778\n",
      "Loss = 0.009066888963755779 | Training Accuracy = 0.2815238095238095 | Val Loss = 0.010945818817294508 | Val Accuracy = 0.2752777777777778\n",
      "Loss = 0.008987583599332806 | Training Accuracy = 0.2784761904761905 | Val Loss = 0.010981748830610781 | Val Accuracy = 0.2746111111111111\n",
      "Loss = 0.008984005988321112 | Training Accuracy = 0.2727142857142857 | Val Loss = 0.011034695946168134 | Val Accuracy = 0.268\n",
      "Loss = 0.0091137462317213 | Training Accuracy = 0.28073809523809523 | Val Loss = 0.010960665132053094 | Val Accuracy = 0.27405555555555555\n",
      "Loss = 0.009068015159450172 | Training Accuracy = 0.284 | Val Loss = 0.01102868619059149 | Val Accuracy = 0.2801111111111111\n",
      "Loss = 0.009042792580959913 | Training Accuracy = 0.2752380952380952 | Val Loss = 0.010967729472621361 | Val Accuracy = 0.27061111111111114\n",
      "Loss = 0.009041196717669363 | Training Accuracy = 0.2878809523809524 | Val Loss = 0.010949748804673337 | Val Accuracy = 0.2836111111111111\n",
      "Loss = 0.009002709599986208 | Training Accuracy = 0.26721428571428574 | Val Loss = 0.011035589236762846 | Val Accuracy = 0.26116666666666666\n",
      "Loss = 0.009103784232138349 | Training Accuracy = 0.28176190476190477 | Val Loss = 0.010927117083571199 | Val Accuracy = 0.2776666666666667\n",
      "Loss = 0.008944808282323063 | Training Accuracy = 0.2793095238095238 | Val Loss = 0.010926771765881858 | Val Accuracy = 0.2728333333333333\n",
      "Loss = 0.008997773577140475 | Training Accuracy = 0.2825714285714286 | Val Loss = 0.0109447057075881 | Val Accuracy = 0.2793333333333333\n",
      "Loss = 0.008983181112892875 | Training Accuracy = 0.2802857142857143 | Val Loss = 0.010964675136866359 | Val Accuracy = 0.2748888888888889\n",
      "Loss = 0.009004507247969274 | Training Accuracy = 0.27976190476190477 | Val Loss = 0.010938699211840423 | Val Accuracy = 0.27755555555555556\n",
      "Loss = 0.009011256584381233 | Training Accuracy = 0.2795 | Val Loss = 0.010963373073620691 | Val Accuracy = 0.2738333333333333\n",
      "Loss = 0.008976395850330549 | Training Accuracy = 0.2856904761904762 | Val Loss = 0.0109725930183101 | Val Accuracy = 0.2803888888888889\n",
      "Loss = 0.008971964300626856 | Training Accuracy = 0.2752857142857143 | Val Loss = 0.011007137764949528 | Val Accuracy = 0.26811111111111113\n",
      "Loss = 0.008997506030778294 | Training Accuracy = 0.2831666666666667 | Val Loss = 0.010922345677245123 | Val Accuracy = 0.2787777777777778\n",
      "Loss = 0.009025871010745298 | Training Accuracy = 0.2809761904761905 | Val Loss = 0.010940877130555 | Val Accuracy = 0.275\n",
      "Loss = 0.008885094093377913 | Training Accuracy = 0.2828333333333333 | Val Loss = 0.010913185160953305 | Val Accuracy = 0.2782222222222222\n",
      "Loss = 0.009043567211769063 | Training Accuracy = 0.2809761904761905 | Val Loss = 0.010920838432604855 | Val Accuracy = 0.2773333333333333\n",
      "Loss = 0.00898545184008927 | Training Accuracy = 0.27985714285714286 | Val Loss = 0.01092519954125304 | Val Accuracy = 0.2753888888888889\n",
      "Loss = 0.009033454450228656 | Training Accuracy = 0.28314285714285714 | Val Loss = 0.010940234923061502 | Val Accuracy = 0.27905555555555556\n",
      "Loss = 0.008986304940081347 | Training Accuracy = 0.2826666666666667 | Val Loss = 0.010932751374800544 | Val Accuracy = 0.2765\n",
      "Loss = 0.009006152431808039 | Training Accuracy = 0.2795238095238095 | Val Loss = 0.010918566549501274 | Val Accuracy = 0.2737222222222222\n",
      "Loss = 0.008977744101653322 | Training Accuracy = 0.2835952380952381 | Val Loss = 0.010899894281729113 | Val Accuracy = 0.27855555555555556\n",
      "Loss = 0.00896775241947201 | Training Accuracy = 0.2839761904761905 | Val Loss = 0.010923298758746735 | Val Accuracy = 0.2813333333333333\n",
      "Loss = 0.00898782510874636 | Training Accuracy = 0.28273809523809523 | Val Loss = 0.010913634556403588 | Val Accuracy = 0.2776111111111111\n",
      "Loss = 0.00900357393289644 | Training Accuracy = 0.28026190476190477 | Val Loss = 0.010950333102472178 | Val Accuracy = 0.2756111111111111\n",
      "Loss = 0.008982018404424646 | Training Accuracy = 0.282 | Val Loss = 0.01094278982638977 | Val Accuracy = 0.27566666666666667\n",
      "Loss = 0.008909263128415954 | Training Accuracy = 0.27985714285714286 | Val Loss = 0.01090474577127343 | Val Accuracy = 0.27344444444444443\n",
      "Loss = 0.008922503216572675 | Training Accuracy = 0.28395238095238096 | Val Loss = 0.010925365339236407 | Val Accuracy = 0.27944444444444444\n",
      "Loss = 0.008990255711255134 | Training Accuracy = 0.2794285714285714 | Val Loss = 0.011010083909117195 | Val Accuracy = 0.2725\n",
      "Loss = 0.008905220431292148 | Training Accuracy = 0.26416666666666666 | Val Loss = 0.010979435776757855 | Val Accuracy = 0.26055555555555554\n",
      "Loss = 0.009001065782113347 | Training Accuracy = 0.2695714285714286 | Val Loss = 0.011005525644826514 | Val Accuracy = 0.26316666666666666\n",
      "Loss = 0.008965996391153102 | Training Accuracy = 0.2781904761904762 | Val Loss = 0.010976052467880443 | Val Accuracy = 0.27211111111111114\n",
      "Loss = 0.008918329704252168 | Training Accuracy = 0.25726190476190475 | Val Loss = 0.011024375764607026 | Val Accuracy = 0.25244444444444447\n",
      "Loss = 0.009045775095608978 | Training Accuracy = 0.2770952380952381 | Val Loss = 0.010948821868713354 | Val Accuracy = 0.2717777777777778\n",
      "Loss = 0.008989239417382089 | Training Accuracy = 0.28145238095238095 | Val Loss = 0.01094009480059843 | Val Accuracy = 0.27666666666666667\n",
      "Loss = 0.008969012723673208 | Training Accuracy = 0.27445238095238095 | Val Loss = 0.010956131147546545 | Val Accuracy = 0.26916666666666667\n",
      "Loss = 0.008990623960634015 | Training Accuracy = 0.28273809523809523 | Val Loss = 0.010917686180011626 | Val Accuracy = 0.2775\n",
      "Loss = 0.008960375844614971 | Training Accuracy = 0.2759285714285714 | Val Loss = 0.010920695901583845 | Val Accuracy = 0.27161111111111114\n",
      "Loss = 0.009000864566452382 | Training Accuracy = 0.27835714285714286 | Val Loss = 0.01096138538238365 | Val Accuracy = 0.27211111111111114\n",
      "Loss = 0.008966939070596288 | Training Accuracy = 0.27376190476190476 | Val Loss = 0.010945381420158669 | Val Accuracy = 0.2685\n",
      "Loss = 0.008920949075553884 | Training Accuracy = 0.2781190476190476 | Val Loss = 0.010928775644788918 | Val Accuracy = 0.2718888888888889\n",
      "Loss = 0.008936200877689544 | Training Accuracy = 0.27654761904761904 | Val Loss = 0.010964887519387097 | Val Accuracy = 0.27105555555555555\n",
      "Loss = 0.008927291318123745 | Training Accuracy = 0.2798095238095238 | Val Loss = 0.010943478907785104 | Val Accuracy = 0.27294444444444443\n",
      "Loss = 0.008951234398080835 | Training Accuracy = 0.2737142857142857 | Val Loss = 0.010929559829233467 | Val Accuracy = 0.2682777777777778\n",
      "Loss = 0.008958062879452111 | Training Accuracy = 0.2773809523809524 | Val Loss = 0.010941790252611022 | Val Accuracy = 0.2732222222222222\n",
      "Loss = 0.009065427273424714 | Training Accuracy = 0.27714285714285714 | Val Loss = 0.010967176096269286 | Val Accuracy = 0.2718888888888889\n",
      "Loss = 0.008934130211974511 | Training Accuracy = 0.2799285714285714 | Val Loss = 0.01094023487465076 | Val Accuracy = 0.27466666666666667\n",
      "Loss = 0.00897328749865025 | Training Accuracy = 0.2786904761904762 | Val Loss = 0.010920815968252347 | Val Accuracy = 0.2743333333333333\n",
      "Loss = 0.009013444428104605 | Training Accuracy = 0.266 | Val Loss = 0.010921591853989339 | Val Accuracy = 0.2608333333333333\n",
      "Loss = 0.008942850258769156 | Training Accuracy = 0.2703809523809524 | Val Loss = 0.010958310196675812 | Val Accuracy = 0.26561111111111113\n",
      "Loss = 0.009028288216950937 | Training Accuracy = 0.2820952380952381 | Val Loss = 0.010918657553940163 | Val Accuracy = 0.2772222222222222\n",
      "Loss = 0.009011371826635568 | Training Accuracy = 0.2723809523809524 | Val Loss = 0.010964435755183887 | Val Accuracy = 0.26661111111111113\n",
      "Loss = 0.009053137294827042 | Training Accuracy = 0.27873809523809523 | Val Loss = 0.010901474482837716 | Val Accuracy = 0.2735\n",
      "Loss = 0.009027941242104973 | Training Accuracy = 0.27295238095238095 | Val Loss = 0.010964470345269347 | Val Accuracy = 0.2672777777777778\n",
      "Loss = 0.008960781233104188 | Training Accuracy = 0.27985714285714286 | Val Loss = 0.010910671315097355 | Val Accuracy = 0.2751111111111111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "## input size\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "## hyperparameters\n",
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "hidden_nodes = 32\n",
    "output_nodes = 10\n",
    "\n",
    "## define neural net\n",
    "nn = NN()\n",
    "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "nn.add_layer(ReLU())\n",
    "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
    "\n",
    "nn = train(nn, X_train , y_train1, minibatch_size=200, epoch=100, \\\n",
    "           learning_rate=learning_rate, X_val=X_test, y_val=y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "3wj1QYfMDcKm",
    "outputId": "96036c29-9452-40bb-b322-34a0d4e6f93b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f842a890ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0].reshape(32,32), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dz1IAlf4DhqW"
   },
   "outputs": [],
   "source": [
    "# Predict Scores for each class\n",
    "prediction = nn.predict_scores(X_test[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "-zOxthaJDxFq",
    "outputId": "ae88f085-a0e3-4707-f1bd-a176d7fbb2a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[ 0.12233832  0.07712824  0.0026162  -0.10811127 -0.01489851 -0.02053064\n",
      " -0.06009443 -0.01255023  0.02048794 -0.00638563]\n"
     ]
    }
   ],
   "source": [
    "print (\"Scores\")\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mxt3nRhISPdw",
    "outputId": "a0a51578-519d-4d9a-fe2b-143bb82575f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RRTR-9BRSUaG",
    "outputId": "3c61ca34-831e-462c-88e5-1e75531b207b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class = nn.predict(X_test[0])[0]\n",
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2l7W5sOBSWV_",
    "outputId": "63db8d2c-beac-4b0a-e1c5-2e46ed37051b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original class\n",
    "y_test1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JihN_UFaQbA2"
   },
   "source": [
    "**As you can see this model did not do well as the accuraccy is 0.25 and the prediction is not accurate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlQgbqBM53P0"
   },
   "source": [
    "**b. Create Model 2 with Sequential with Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXi3zLx2VgUn"
   },
   "source": [
    "\n",
    "**One-hot encode the class vector**\n",
    "* convert class vectors (integers) to binary class matrix\n",
    "* convert X_train and X_val\n",
    "* number of classes: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "W7pLT1PSUu9i",
    "outputId": "49980501-e3b7-404c-fe7e-53deadee01c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train1[10])\n",
    "y_train1 = tensorflow.keras.utils.to_categorical(y_train1, num_classes=10)\n",
    "y_test1 = tensorflow.keras.utils.to_categorical(y_test1, num_classes=10)\n",
    "print(y_train1[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsmSJCO0Vzy6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "\n",
    "#def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "iterations = 10\n",
    "learning_rate = 0.00001\n",
    "hidden_nodes = 256\n",
    "output_nodes = 10\n",
    "        \n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "model.add(Dense(hidden_nodes, activation='relu'))\n",
    "model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(0)))\n",
    "   \n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "   # Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "#model.fit(X_train, y_train, epochs=iterations, batch_size=1000, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "9hxu_F5Xfh86",
    "outputId": "25f9be6b-b7d2-463e-aa61-4c2e88064483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3530 - accuracy: 0.0999\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3488 - accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3449 - accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3415 - accuracy: 0.1001\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3384 - accuracy: 0.1003\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3356 - accuracy: 0.1005\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3331 - accuracy: 0.1008\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3309 - accuracy: 0.1010\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3289 - accuracy: 0.1016\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3271 - accuracy: 0.1016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab5e0ae160>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train1, epochs=iterations, batch_size=1000, verbose= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzX6puFhvup8"
   },
   "source": [
    "\n",
    "> **Creating model 2**\n",
    "\n",
    "* Same model as above\n",
    "* Instead of accuracy at each epoch below code gives the consolidate accuracy\n",
    "* Notice: The model.evaluate line at the last is the only difference from model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK_sBdIGv3rc"
   },
   "outputs": [],
   "source": [
    "def train_and_test_loop1(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 256\n",
    "    output_nodes = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_nodes, input_shape=(1024,), activation='relu'))\n",
    "    model.add(Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train1, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(X_train, y_train1, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpUFNthvv9Ff"
   },
   "source": [
    "**Next steps**\n",
    "* Double Check that the loss is reasonable\n",
    "* Disable the regularization (Lambda = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "U_KN6SjTwEJ0",
    "outputId": "ecccd5ff-8331-4ad9-e2f6-2517a283cf7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3193 - accuracy: 0.1001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3184993267059326, 0.10019047558307648]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "Lambda = 0\n",
    "train_and_test_loop1(1, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dxMiyVzwkWQ"
   },
   "source": [
    "**Now, lets crank up the Lambda(Regularization)and check what it does to our loss function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZ55zrAnwjLR"
   },
   "outputs": [],
   "source": [
    "X_train_subset = X_train[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykAv3T-Ywr1p"
   },
   "outputs": [],
   "source": [
    "y_train_subset = y_train1[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDXiLKwLwv3G"
   },
   "outputs": [],
   "source": [
    "X_train = X_train_subset\n",
    "y_train1 = y_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9CgF5-cFwvzh",
    "outputId": "32d99925-201f-4730-ba3c-5c06bf1a153e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1024)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0OwGmNzKwvvy",
    "outputId": "707073e9-5c30-42e8-d981-8211a2ff3a99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wL1iPrrow7bk"
   },
   "source": [
    "In the code below:\n",
    "* Take the first 20 examples from SVHN\n",
    "* turn off regularization(reg=0.0)\n",
    "* use simple vanilla 'sgd'\n",
    "* Lets try and run for 500 iterations as the data set is very small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "N8cAcVK2xCdz",
    "outputId": "bca06c2a-8ac4-444a-d9a1-da2a53414e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5094 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4852 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 952us/step - loss: 2.4417 - accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3846 - accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3196 - accuracy: 0.1500\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2508 - accuracy: 0.2500\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1843 - accuracy: 0.2500\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 883us/step - loss: 2.1229 - accuracy: 0.2500\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0689 - accuracy: 0.2500\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0228 - accuracy: 0.2500\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9827 - accuracy: 0.2500\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9490 - accuracy: 0.2500\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 850us/step - loss: 1.9209 - accuracy: 0.2500\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8962 - accuracy: 0.3000\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8755 - accuracy: 0.3500\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 967us/step - loss: 1.8576 - accuracy: 0.3000\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8424 - accuracy: 0.3000\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8292 - accuracy: 0.4000\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8177 - accuracy: 0.4000\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8074 - accuracy: 0.4000\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7980 - accuracy: 0.4000\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7892 - accuracy: 0.4000\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7807 - accuracy: 0.4000\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7722 - accuracy: 0.5000\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7640 - accuracy: 0.5500\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7557 - accuracy: 0.5500\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7471 - accuracy: 0.5500\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7386 - accuracy: 0.5500\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7302 - accuracy: 0.5500\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7218 - accuracy: 0.5500\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7138 - accuracy: 0.5500\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7057 - accuracy: 0.5500\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6977 - accuracy: 0.5500\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6896 - accuracy: 0.5500\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6817 - accuracy: 0.5500\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6738 - accuracy: 0.5500\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6662 - accuracy: 0.5500\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6586 - accuracy: 0.5500\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6513 - accuracy: 0.5500\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6440 - accuracy: 0.5500\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6368 - accuracy: 0.5500\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6295 - accuracy: 0.5500\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6223 - accuracy: 0.5500\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6152 - accuracy: 0.5500\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6083 - accuracy: 0.5500\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6016 - accuracy: 0.5500\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5950 - accuracy: 0.5500\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5885 - accuracy: 0.5500\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5820 - accuracy: 0.5500\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5754 - accuracy: 0.5500\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5688 - accuracy: 0.5500\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5623 - accuracy: 0.5500\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5558 - accuracy: 0.5500\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5494 - accuracy: 0.5500\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5431 - accuracy: 0.5500\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5369 - accuracy: 0.5500\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5307 - accuracy: 0.5500\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5247 - accuracy: 0.5500\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5189 - accuracy: 0.5500\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5130 - accuracy: 0.5500\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5070 - accuracy: 0.5500\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5011 - accuracy: 0.5500\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4952 - accuracy: 0.5500\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4893 - accuracy: 0.5500\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4835 - accuracy: 0.5500\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4777 - accuracy: 0.5500\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4719 - accuracy: 0.6000\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4661 - accuracy: 0.6000\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4604 - accuracy: 0.6000\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4546 - accuracy: 0.6000\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4488 - accuracy: 0.6000\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4429 - accuracy: 0.6000\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4371 - accuracy: 0.6000\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4314 - accuracy: 0.6000\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4258 - accuracy: 0.6000\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4202 - accuracy: 0.6000\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4147 - accuracy: 0.6000\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4092 - accuracy: 0.6000\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4037 - accuracy: 0.6000\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3982 - accuracy: 0.6000\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3927 - accuracy: 0.6000\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3871 - accuracy: 0.6000\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3816 - accuracy: 0.6000\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3761 - accuracy: 0.6000\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3706 - accuracy: 0.6000\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3651 - accuracy: 0.6000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3596 - accuracy: 0.6000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3541 - accuracy: 0.6500\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3486 - accuracy: 0.6500\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3430 - accuracy: 0.6500\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3373 - accuracy: 0.6500\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3317 - accuracy: 0.6500\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3260 - accuracy: 0.6500\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3204 - accuracy: 0.6500\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3147 - accuracy: 0.6500\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3089 - accuracy: 0.6500\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3032 - accuracy: 0.6500\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2974 - accuracy: 0.6500\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2916 - accuracy: 0.6500\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2857 - accuracy: 0.6500\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2798 - accuracy: 0.6500\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2740 - accuracy: 0.6500\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2682 - accuracy: 0.6500\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2624 - accuracy: 0.6500\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2567 - accuracy: 0.6500\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2511 - accuracy: 0.6500\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2456 - accuracy: 0.6500\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2400 - accuracy: 0.6500\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2344 - accuracy: 0.6500\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2289 - accuracy: 0.6500\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2234 - accuracy: 0.6500\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2181 - accuracy: 0.6500\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2127 - accuracy: 0.6500\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2073 - accuracy: 0.6500\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2018 - accuracy: 0.6500\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1964 - accuracy: 0.6500\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1911 - accuracy: 0.6500\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1857 - accuracy: 0.6500\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1804 - accuracy: 0.6500\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1750 - accuracy: 0.6500\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1696 - accuracy: 0.6500\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1642 - accuracy: 0.6500\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1589 - accuracy: 0.7000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1536 - accuracy: 0.7000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1482 - accuracy: 0.7000\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1430 - accuracy: 0.7000\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1377 - accuracy: 0.7000\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1325 - accuracy: 0.7000\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1273 - accuracy: 0.7000\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1222 - accuracy: 0.7000\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1170 - accuracy: 0.7000\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1118 - accuracy: 0.7000\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1066 - accuracy: 0.7500\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1015 - accuracy: 0.7500\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0964 - accuracy: 0.7500\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0912 - accuracy: 0.8000\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0861 - accuracy: 0.8000\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0810 - accuracy: 0.8000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0760 - accuracy: 0.8000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0709 - accuracy: 0.8000\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0659 - accuracy: 0.8000\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0609 - accuracy: 0.8000\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0558 - accuracy: 0.8000\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0509 - accuracy: 0.8000\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0458 - accuracy: 0.8000\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0409 - accuracy: 0.8000\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0359 - accuracy: 0.8000\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0309 - accuracy: 0.8000\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.8000\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0209 - accuracy: 0.8000\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0159 - accuracy: 0.8000\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0110 - accuracy: 0.8000\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0060 - accuracy: 0.8000\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0011 - accuracy: 0.8000\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9962 - accuracy: 0.8000\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9913 - accuracy: 0.8000\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9864 - accuracy: 0.8000\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9815 - accuracy: 0.8000\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9766 - accuracy: 0.8000\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9716 - accuracy: 0.8000\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9668 - accuracy: 0.8000\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9620 - accuracy: 0.8000\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9572 - accuracy: 0.8000\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9524 - accuracy: 0.8000\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9475 - accuracy: 0.8000\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9427 - accuracy: 0.8000\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9379 - accuracy: 0.8000\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.8000\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9281 - accuracy: 0.8000\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9232 - accuracy: 0.8000\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.8000\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9136 - accuracy: 0.8000\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9088 - accuracy: 0.8000\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9041 - accuracy: 0.8000\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8994 - accuracy: 0.8000\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.8000\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8899 - accuracy: 0.8000\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8851 - accuracy: 0.8000\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8804 - accuracy: 0.8000\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8757 - accuracy: 0.8000\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8711 - accuracy: 0.8000\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8664 - accuracy: 0.8000\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8618 - accuracy: 0.8000\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8572 - accuracy: 0.8000\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8527 - accuracy: 0.8000\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8482 - accuracy: 0.8000\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8437 - accuracy: 0.8000\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8392 - accuracy: 0.8000\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8347 - accuracy: 0.8000\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8302 - accuracy: 0.8000\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8257 - accuracy: 0.8000\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8211 - accuracy: 0.8000\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8166 - accuracy: 0.8000\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8121 - accuracy: 0.8000\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8076 - accuracy: 0.8000\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8031 - accuracy: 0.8500\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7986 - accuracy: 0.8500\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7942 - accuracy: 0.8500\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7899 - accuracy: 0.8500\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7855 - accuracy: 0.8500\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7812 - accuracy: 0.9000\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7768 - accuracy: 0.9000\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7726 - accuracy: 0.9000\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7683 - accuracy: 0.9000\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7640 - accuracy: 0.9000\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7597 - accuracy: 0.9000\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.9000\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7514 - accuracy: 0.9000\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7472 - accuracy: 0.9000\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7431 - accuracy: 0.9000\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7389 - accuracy: 0.9000\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7349 - accuracy: 0.9000\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.9000\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7268 - accuracy: 0.9000\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.9000\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7187 - accuracy: 0.9000\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.9000\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.9000\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.9500\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.9500\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.9500\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.9500\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.9500\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.9500\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.9500\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.9500\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.9500\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.9500\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.9500\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.9500\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.9500\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.9500\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.5366 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4570 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2974 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2939 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2772 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2693 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2558 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14368698000907898, 1.0]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "Lambda = 0\n",
    "train_and_test_loop1(500, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rr1UOC7vxnvH"
   },
   "source": [
    "**Very small loss, train accuracy going to 100, nice! We are successful in overfitting. The model architecture looks fine. Lets go for fine tuning it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6CywEy6xzGS"
   },
   "source": [
    "**Loading the original dataset again**\n",
    "\n",
    "**Import dataset**\n",
    "* This dataset can be imported\n",
    "* High level API Keras has some datasets available\n",
    "* h5py.FIle() returns two tuples (x_train, y_train1), (x_test, y_test1):\n",
    " * x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 32, 32)\n",
    " * y_test1, y_test1: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3TFK14gxt9A"
   },
   "outputs": [],
   "source": [
    "#Open the file as readonly/content/drive/My Drive/SVHN_single_grey1.h5\n",
    "h5f = h5py.File('/content/drive/My Drive/SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuVgrc8cxt5r"
   },
   "outputs": [],
   "source": [
    "# Load the training, test / validation test\n",
    "X_train= h5f['X_train'][:]\n",
    "y_train1= h5f['y_train'][:]\n",
    "X_test= h5f['X_test'][:]\n",
    "y_test1= h5f['y_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uS8dvT0zye51"
   },
   "source": [
    "**Reshape Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "gtz-VkNPxtxr",
    "outputId": "51b1f019-49d4-46e5-fe43-fadc877f8912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(42000, 1024)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(18000, 1024)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsdQHAjPy5XM"
   },
   "source": [
    "\n",
    "**Normalize features**\n",
    "* Normalize features from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sc1eDW4Ey6FN"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OHwz2brHzFPD"
   },
   "source": [
    "**One Hot Encoder**\n",
    "* convert class vectors (integers) to binary class matrix\n",
    "* convert X_train and X_val\n",
    "* number of classes: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-H-CJYoHzM6B"
   },
   "outputs": [],
   "source": [
    "y_train1 = tensorflow.keras.utils.to_categorical(y_train1, num_classes=10)\n",
    "y_test1 = tensorflow.keras.utils.to_categorical(y_test1, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBi80mKszWkR"
   },
   "source": [
    "\n",
    "**Start with small regularization and find learning rate that makes the loss go down.**\n",
    "* we start with Lambda(small regularization) = 1e-7\n",
    "* we start with a small learning rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "CMy4_3PrzT9K",
    "outputId": "3c1e7ea8-f9cd-4d41-be6a-87c441a6ee9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3640 - accuracy: 0.0998\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3639 - accuracy: 0.0997\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3638 - accuracy: 0.0998\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3638 - accuracy: 0.0998\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3637 - accuracy: 0.0998\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3636 - accuracy: 0.0998\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3635 - accuracy: 0.0998\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3635 - accuracy: 0.0998\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3634 - accuracy: 0.0998\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3633 - accuracy: 0.0998\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3633 - accuracy: 0.0998\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3632 - accuracy: 0.0997\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3631 - accuracy: 0.0998\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3631 - accuracy: 0.0998\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3630 - accuracy: 0.0998\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3629 - accuracy: 0.0997\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3628 - accuracy: 0.0998\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3628 - accuracy: 0.0998\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3627 - accuracy: 0.0997\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3626 - accuracy: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.362602710723877, 0.09971428662538528]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-7\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop1(20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ob3CX0dUzucw"
   },
   "source": [
    "\n",
    "**Loss barely changing. Learning rate is probably too low.**\n",
    "\n",
    "**Okay now lets try a (larger) learning rate 1e6. What could possibly go wrong?**\n",
    "* Learning rate lr = 1e8\n",
    "* Regularization lambda = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "j-FCPrkfz7XE",
    "outputId": "2c5b1fdc-2653-486f-f5fa-f3a1222237bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0994\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.09966666996479034]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e8\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop1(20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCtAlm480NbU"
   },
   "source": [
    "**Loss exploding. Learning rate is too high.**\n",
    "**Cost is very high. Always means high learning rate**\n",
    "\n",
    "**Lets try to train now with a value of learning rate between 1e-7 and 1e8**\n",
    "* learning rate = 1e4\n",
    "* regularization remains the small, lambda = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "mRTr00vY0N_H",
    "outputId": "13a9b030-6c86-4315-e245-350306d7598e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0990\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.09966666996479034]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e4\n",
    "Lambda = 1e-7\n",
    "train_and_test_loop1(20, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw3TMv9v1pAT"
   },
   "source": [
    "**Still too high learning rate. Loss is not decreasing. The rough range of learning rate we should be cross validating is somewhere between [1e3 to 1e-7]**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ei77rAMb1rgN"
   },
   "source": [
    "**Hyperparameter Optimization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JLWK96pe1oYu",
    "outputId": "42e5ddcc-e3b2-4908-c42c-63d0ad411bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3074 - accuracy: 0.1059\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2933 - accuracy: 0.1245\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2866 - accuracy: 0.1408\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2802 - accuracy: 0.1602\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2739 - accuracy: 0.1728\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2676 - accuracy: 0.1917\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2604 - accuracy: 0.2132\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2527 - accuracy: 0.2323\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2445 - accuracy: 0.2427\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2357 - accuracy: 0.2629\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2254 - accuracy: 0.2786\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2150 - accuracy: 0.2969\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2034 - accuracy: 0.3137\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1911 - accuracy: 0.3290\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1780 - accuracy: 0.3412\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1631 - accuracy: 0.3573\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1474 - accuracy: 0.3650\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1301 - accuracy: 0.3786\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1115 - accuracy: 0.3930\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0914 - accuracy: 0.4022\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0700 - accuracy: 0.4119\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0470 - accuracy: 0.4192\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0232 - accuracy: 0.4333\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9981 - accuracy: 0.4381\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9714 - accuracy: 0.4521\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9438 - accuracy: 0.4586\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9158 - accuracy: 0.4695\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.8872 - accuracy: 0.4774\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8583 - accuracy: 0.4864\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8300 - accuracy: 0.4968\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8014 - accuracy: 0.5050\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7734 - accuracy: 0.5140\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7464 - accuracy: 0.5216\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7200 - accuracy: 0.5276\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6934 - accuracy: 0.5359\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6685 - accuracy: 0.5438\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6438 - accuracy: 0.5508\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6199 - accuracy: 0.5588\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5977 - accuracy: 0.5636\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5749 - accuracy: 0.5695\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5533 - accuracy: 0.5762\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5322 - accuracy: 0.5823\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5120 - accuracy: 0.5880\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4932 - accuracy: 0.5905\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.4739 - accuracy: 0.5957\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.4559 - accuracy: 0.6015\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4383 - accuracy: 0.6036\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4216 - accuracy: 0.6078\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4058 - accuracy: 0.6108\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3904 - accuracy: 0.6154\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3747 - accuracy: 0.6181\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3608 - accuracy: 0.6212\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3458 - accuracy: 0.6237\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3331 - accuracy: 0.6279\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3201 - accuracy: 0.6299\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3076 - accuracy: 0.6333\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2948 - accuracy: 0.6356\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2838 - accuracy: 0.6384\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2715 - accuracy: 0.6415\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2627 - accuracy: 0.6431\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2509 - accuracy: 0.6455\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2399 - accuracy: 0.6491\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2308 - accuracy: 0.6517\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2233 - accuracy: 0.6519\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2123 - accuracy: 0.6557\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2042 - accuracy: 0.6573\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1943 - accuracy: 0.6609\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1859 - accuracy: 0.6615\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1787 - accuracy: 0.6621\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1725 - accuracy: 0.6641\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1628 - accuracy: 0.6679\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1560 - accuracy: 0.6682\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1495 - accuracy: 0.6693\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1425 - accuracy: 0.6702\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1343 - accuracy: 0.6739\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1271 - accuracy: 0.6757\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1203 - accuracy: 0.6765\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1144 - accuracy: 0.6781\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1084 - accuracy: 0.6799\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1029 - accuracy: 0.6808\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0963 - accuracy: 0.6822\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0901 - accuracy: 0.6840\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0862 - accuracy: 0.6838\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0803 - accuracy: 0.6865\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0754 - accuracy: 0.6880\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0687 - accuracy: 0.6893\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0640 - accuracy: 0.6903\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0572 - accuracy: 0.6919\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0528 - accuracy: 0.6943\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0476 - accuracy: 0.6947\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0426 - accuracy: 0.6958\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0396 - accuracy: 0.6972\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0339 - accuracy: 0.6992\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0292 - accuracy: 0.6977\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0252 - accuracy: 0.7001\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0193 - accuracy: 0.7011\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0149 - accuracy: 0.7034\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0115 - accuracy: 0.7031\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0075 - accuracy: 0.7047\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0029 - accuracy: 0.7063\n",
      "Try 1/100: Best_val_acc: [1.0011625289916992, 0.7054286003112793], lr: 0.0018756428710766816, Lambda: 1.8243877887278565e-06\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3897 - accuracy: 0.1011\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3769 - accuracy: 0.1015\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3660 - accuracy: 0.1021\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3571 - accuracy: 0.1028\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3497 - accuracy: 0.1044\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3435 - accuracy: 0.1060\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3383 - accuracy: 0.1054\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3338 - accuracy: 0.1059\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3300 - accuracy: 0.1048\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3267 - accuracy: 0.1044\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3239 - accuracy: 0.1032\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3214 - accuracy: 0.1029\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3192 - accuracy: 0.1026\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3173 - accuracy: 0.1024\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3157 - accuracy: 0.1028\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3143 - accuracy: 0.1024\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3130 - accuracy: 0.1018\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3118 - accuracy: 0.1016\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3109 - accuracy: 0.1014\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3100 - accuracy: 0.1012\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3092 - accuracy: 0.1008\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3085 - accuracy: 0.1012\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3078 - accuracy: 0.1010\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3073 - accuracy: 0.1005\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3068 - accuracy: 0.1007\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3063 - accuracy: 0.1008\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3059 - accuracy: 0.1003\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3055 - accuracy: 0.1009\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3052 - accuracy: 0.1009\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3049 - accuracy: 0.1011\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3046 - accuracy: 0.1014\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3044 - accuracy: 0.1016\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3041 - accuracy: 0.1020\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3039 - accuracy: 0.1018\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3037 - accuracy: 0.1018\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3035 - accuracy: 0.1018\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3033 - accuracy: 0.1023\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3032 - accuracy: 0.1029\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3030 - accuracy: 0.1029\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3029 - accuracy: 0.1039\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3027 - accuracy: 0.1045\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3026 - accuracy: 0.1051\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3025 - accuracy: 0.1053\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3023 - accuracy: 0.1053\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3022 - accuracy: 0.1057\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3021 - accuracy: 0.1061\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3020 - accuracy: 0.1065\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3019 - accuracy: 0.1068\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3018 - accuracy: 0.1072\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3017 - accuracy: 0.1073\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3016 - accuracy: 0.1074\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3015 - accuracy: 0.1083\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3014 - accuracy: 0.1083\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3014 - accuracy: 0.1086\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3013 - accuracy: 0.1089\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3012 - accuracy: 0.1088\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3011 - accuracy: 0.1091\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3011 - accuracy: 0.1088\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3010 - accuracy: 0.1090\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3009 - accuracy: 0.1091\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3008 - accuracy: 0.1093\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3008 - accuracy: 0.1095\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3007 - accuracy: 0.1098\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3006 - accuracy: 0.1098\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3005 - accuracy: 0.1100\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3005 - accuracy: 0.1099\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3004 - accuracy: 0.1103\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3003 - accuracy: 0.1099\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3003 - accuracy: 0.1098\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3002 - accuracy: 0.1103\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3002 - accuracy: 0.1101\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3001 - accuracy: 0.1104\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3000 - accuracy: 0.1102\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3000 - accuracy: 0.1107\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2999 - accuracy: 0.1108\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2998 - accuracy: 0.1107\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2998 - accuracy: 0.1110\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2997 - accuracy: 0.1114\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2997 - accuracy: 0.1117\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2996 - accuracy: 0.1120\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2995 - accuracy: 0.1120\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2995 - accuracy: 0.1120\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2994 - accuracy: 0.1122\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2994 - accuracy: 0.1126\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2993 - accuracy: 0.1125\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2992 - accuracy: 0.1125\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2992 - accuracy: 0.1128\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2991 - accuracy: 0.1130\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2991 - accuracy: 0.1127\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2990 - accuracy: 0.1131\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2989 - accuracy: 0.1131\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2989 - accuracy: 0.1132\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2988 - accuracy: 0.1132\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2988 - accuracy: 0.1132\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2987 - accuracy: 0.1136\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2987 - accuracy: 0.1137\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2986 - accuracy: 0.1143\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2986 - accuracy: 0.1142\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2985 - accuracy: 0.1145\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2984 - accuracy: 0.1143\n",
      "Try 2/100: Best_val_acc: [2.2984156608581543, 0.11459523439407349], lr: 1.2927087874196569e-05, Lambda: 9.394284322512174e-05\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3598 - accuracy: 0.1026\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3193 - accuracy: 0.1059\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3081 - accuracy: 0.1069\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3051 - accuracy: 0.1070\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3038 - accuracy: 0.1072\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3032 - accuracy: 0.1065\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3026 - accuracy: 0.1071\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3021 - accuracy: 0.1081\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3016 - accuracy: 0.1092\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3011 - accuracy: 0.1099\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3006 - accuracy: 0.1115\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3001 - accuracy: 0.1128\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2997 - accuracy: 0.1135\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2992 - accuracy: 0.1156\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2988 - accuracy: 0.1167\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2984 - accuracy: 0.1187\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2980 - accuracy: 0.1181\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2976 - accuracy: 0.1195\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2972 - accuracy: 0.1207\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2968 - accuracy: 0.1218\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2965 - accuracy: 0.1225\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2961 - accuracy: 0.1243\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2958 - accuracy: 0.1252\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2954 - accuracy: 0.1268\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2950 - accuracy: 0.1279\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2947 - accuracy: 0.1288\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2943 - accuracy: 0.1298\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2940 - accuracy: 0.1303\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2936 - accuracy: 0.1321\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2933 - accuracy: 0.1329\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2929 - accuracy: 0.1338\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2926 - accuracy: 0.1355\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2922 - accuracy: 0.1355\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2919 - accuracy: 0.1362\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2916 - accuracy: 0.1383\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2912 - accuracy: 0.1390\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2909 - accuracy: 0.1397\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2906 - accuracy: 0.1407\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2903 - accuracy: 0.1417\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2899 - accuracy: 0.1423\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2896 - accuracy: 0.1432\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2893 - accuracy: 0.1448\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2890 - accuracy: 0.1465\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2887 - accuracy: 0.1457\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2884 - accuracy: 0.1472\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2881 - accuracy: 0.1490\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2878 - accuracy: 0.1495\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2875 - accuracy: 0.1496\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2872 - accuracy: 0.1515\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2869 - accuracy: 0.1508\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2866 - accuracy: 0.1531\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2863 - accuracy: 0.1529\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2860 - accuracy: 0.1547\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2857 - accuracy: 0.1551\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2854 - accuracy: 0.1552\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2851 - accuracy: 0.1558\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2848 - accuracy: 0.1564\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2845 - accuracy: 0.1576\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2842 - accuracy: 0.1590\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2839 - accuracy: 0.1597\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2836 - accuracy: 0.1605\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2833 - accuracy: 0.1610\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2830 - accuracy: 0.1618\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2827 - accuracy: 0.1625\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.2824 - accuracy: 0.1635\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2821 - accuracy: 0.1635\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2818 - accuracy: 0.1660\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2815 - accuracy: 0.1670\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2811 - accuracy: 0.1680\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2808 - accuracy: 0.1684\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2805 - accuracy: 0.1687\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2802 - accuracy: 0.1706\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2799 - accuracy: 0.1703\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2796 - accuracy: 0.1711\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2792 - accuracy: 0.1741\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2789 - accuracy: 0.1737\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2786 - accuracy: 0.1750\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2784 - accuracy: 0.1761\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2781 - accuracy: 0.1766\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2778 - accuracy: 0.1764\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2775 - accuracy: 0.1785\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2772 - accuracy: 0.1798\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2769 - accuracy: 0.1786\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2766 - accuracy: 0.1808\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2763 - accuracy: 0.1822\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2760 - accuracy: 0.1816\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2757 - accuracy: 0.1827\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2754 - accuracy: 0.1855\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2751 - accuracy: 0.1865\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2748 - accuracy: 0.1860\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2745 - accuracy: 0.1879\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2742 - accuracy: 0.1879\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2739 - accuracy: 0.1891\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.2736 - accuracy: 0.1896\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2733 - accuracy: 0.1914\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2730 - accuracy: 0.1917\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2727 - accuracy: 0.1936\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2724 - accuracy: 0.1927\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2721 - accuracy: 0.1944\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2718 - accuracy: 0.1935\n",
      "Try 3/100: Best_val_acc: [2.271559238433838, 0.19466666877269745], lr: 0.00012362294034297625, Lambda: 3.138940262598723e-05\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3277 - accuracy: 0.0994\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3056 - accuracy: 0.1004\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3028 - accuracy: 0.1061\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.3011 - accuracy: 0.1109\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2995 - accuracy: 0.1138\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2981 - accuracy: 0.1191\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2967 - accuracy: 0.1206\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2954 - accuracy: 0.1251\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2943 - accuracy: 0.1287\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2932 - accuracy: 0.1301\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.2922 - accuracy: 0.1350\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2913 - accuracy: 0.1362\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2903 - accuracy: 0.1387\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2894 - accuracy: 0.1389\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2884 - accuracy: 0.1433\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2875 - accuracy: 0.1451\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2866 - accuracy: 0.1485\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2856 - accuracy: 0.1516\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2847 - accuracy: 0.1545\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2838 - accuracy: 0.1567\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2829 - accuracy: 0.1604\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2819 - accuracy: 0.1638\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2811 - accuracy: 0.1640\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2801 - accuracy: 0.1704\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2792 - accuracy: 0.1708\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.2783 - accuracy: 0.1735\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.2773 - accuracy: 0.1780\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.2763 - accuracy: 0.1811\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2754 - accuracy: 0.1821\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2744 - accuracy: 0.1842\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2734 - accuracy: 0.1865\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2724 - accuracy: 0.1884\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2714 - accuracy: 0.1916\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2703 - accuracy: 0.1951\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2692 - accuracy: 0.1954\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2681 - accuracy: 0.2010\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2670 - accuracy: 0.2024\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2658 - accuracy: 0.2080\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2647 - accuracy: 0.2076\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2635 - accuracy: 0.2124\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2623 - accuracy: 0.2142\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2611 - accuracy: 0.2160\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2598 - accuracy: 0.2210\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2585 - accuracy: 0.2236\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2574 - accuracy: 0.2254\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2561 - accuracy: 0.2303\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2548 - accuracy: 0.2324\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2536 - accuracy: 0.2334\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.2523 - accuracy: 0.2396\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2511 - accuracy: 0.2387\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2497 - accuracy: 0.2434\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2483 - accuracy: 0.2465\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2470 - accuracy: 0.2489\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2456 - accuracy: 0.2508\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2442 - accuracy: 0.2531\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2427 - accuracy: 0.2568\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2412 - accuracy: 0.2607\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2397 - accuracy: 0.2628\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2381 - accuracy: 0.2670\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2365 - accuracy: 0.2703\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2348 - accuracy: 0.2733\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2332 - accuracy: 0.2794\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2316 - accuracy: 0.2796\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2300 - accuracy: 0.2827\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2283 - accuracy: 0.2853\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2266 - accuracy: 0.2880\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2249 - accuracy: 0.2917\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2232 - accuracy: 0.2945\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2213 - accuracy: 0.2980\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2195 - accuracy: 0.3001\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2177 - accuracy: 0.3028\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2158 - accuracy: 0.3070\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2139 - accuracy: 0.3095\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2120 - accuracy: 0.3134\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2100 - accuracy: 0.3145\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2079 - accuracy: 0.3189\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2059 - accuracy: 0.3186\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2038 - accuracy: 0.3241\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2016 - accuracy: 0.3263\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1995 - accuracy: 0.3295\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1973 - accuracy: 0.3307\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1950 - accuracy: 0.3343\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1928 - accuracy: 0.3380\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1905 - accuracy: 0.3390\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1882 - accuracy: 0.3412\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1858 - accuracy: 0.3451\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1834 - accuracy: 0.3441\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1810 - accuracy: 0.3502\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1785 - accuracy: 0.3533\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1761 - accuracy: 0.3526\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1735 - accuracy: 0.3562\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1709 - accuracy: 0.3575\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1683 - accuracy: 0.3622\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1657 - accuracy: 0.3631\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1630 - accuracy: 0.3642\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1603 - accuracy: 0.3678\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1575 - accuracy: 0.3706\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1547 - accuracy: 0.3713\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1518 - accuracy: 0.3735\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1489 - accuracy: 0.3751\n",
      "Try 4/100: Best_val_acc: [2.147223949432373, 0.37692856788635254], lr: 0.0003479853454866674, Lambda: 9.521113484820502e-06\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3644 - accuracy: 0.0990\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3633 - accuracy: 0.0985\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3622 - accuracy: 0.0984\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3611 - accuracy: 0.0987\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3601 - accuracy: 0.0988\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3591 - accuracy: 0.0992\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3581 - accuracy: 0.0992\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3572 - accuracy: 0.1003\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3563 - accuracy: 0.1006\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3555 - accuracy: 0.1008\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3546 - accuracy: 0.1011\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3538 - accuracy: 0.1010\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3531 - accuracy: 0.1014\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3524 - accuracy: 0.1021\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3516 - accuracy: 0.1024\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3510 - accuracy: 0.1027\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3503 - accuracy: 0.1032\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3497 - accuracy: 0.1035\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3491 - accuracy: 0.1038\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3485 - accuracy: 0.1043\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3479 - accuracy: 0.1044\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3474 - accuracy: 0.1050\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3468 - accuracy: 0.1050\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3463 - accuracy: 0.1051\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3458 - accuracy: 0.1053\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 2.3454 - accuracy: 0.1053\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3449 - accuracy: 0.1055\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3445 - accuracy: 0.1057\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3441 - accuracy: 0.1060\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3436 - accuracy: 0.1063\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3432 - accuracy: 0.1065\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3429 - accuracy: 0.1064\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3425 - accuracy: 0.1065\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3421 - accuracy: 0.1068\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3418 - accuracy: 0.1066\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3415 - accuracy: 0.1063\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3411 - accuracy: 0.1064\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3408 - accuracy: 0.1063\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3405 - accuracy: 0.1061\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3403 - accuracy: 0.1061\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3400 - accuracy: 0.1060\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3397 - accuracy: 0.1059\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3394 - accuracy: 0.1061\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3392 - accuracy: 0.1061\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3389 - accuracy: 0.1064\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3387 - accuracy: 0.1064\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3385 - accuracy: 0.1060\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3383 - accuracy: 0.1059\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3380 - accuracy: 0.1058\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3378 - accuracy: 0.1059\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3376 - accuracy: 0.1060\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3374 - accuracy: 0.1060\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3372 - accuracy: 0.1061\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3371 - accuracy: 0.1065\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3369 - accuracy: 0.1064\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3367 - accuracy: 0.1068\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3365 - accuracy: 0.1068\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3364 - accuracy: 0.1069\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3362 - accuracy: 0.1066\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3361 - accuracy: 0.1061\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3359 - accuracy: 0.1061\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3358 - accuracy: 0.1060\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3356 - accuracy: 0.1061\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3355 - accuracy: 0.1059\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3354 - accuracy: 0.1058\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3352 - accuracy: 0.1057\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3351 - accuracy: 0.1056\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3350 - accuracy: 0.1054\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3349 - accuracy: 0.1051\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3348 - accuracy: 0.1052\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3346 - accuracy: 0.1055\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3345 - accuracy: 0.1051\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3344 - accuracy: 0.1051\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3343 - accuracy: 0.1049\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3342 - accuracy: 0.1049\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3341 - accuracy: 0.1050\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3340 - accuracy: 0.1047\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3339 - accuracy: 0.1049\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3338 - accuracy: 0.1051\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3338 - accuracy: 0.1050\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3337 - accuracy: 0.1050\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3336 - accuracy: 0.1047\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3335 - accuracy: 0.1047\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3334 - accuracy: 0.1047\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3333 - accuracy: 0.1045\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3333 - accuracy: 0.1045\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3332 - accuracy: 0.1045\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3331 - accuracy: 0.1047\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3330 - accuracy: 0.1048\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3330 - accuracy: 0.1048\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3329 - accuracy: 0.1045\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3328 - accuracy: 0.1044\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3328 - accuracy: 0.1045\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3327 - accuracy: 0.1046\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3326 - accuracy: 0.1045\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3326 - accuracy: 0.1044\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3325 - accuracy: 0.1042\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3325 - accuracy: 0.1040\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3324 - accuracy: 0.1038\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3324 - accuracy: 0.1038\n",
      "Try 5/100: Best_val_acc: [2.3323216438293457, 0.10380952060222626], lr: 3.233551353509162e-06, Lambda: 0.0013081663341086157\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4393 - accuracy: 0.0999\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4217 - accuracy: 0.0999\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4062 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3934 - accuracy: 0.0999\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3827 - accuracy: 0.0999\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3736 - accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3659 - accuracy: 0.0999\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3593 - accuracy: 0.0999\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3536 - accuracy: 0.0999\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3487 - accuracy: 0.1001\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3443 - accuracy: 0.1008\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.3405 - accuracy: 0.1009\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3371 - accuracy: 0.1015\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3341 - accuracy: 0.1019\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3315 - accuracy: 0.1025\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3290 - accuracy: 0.1029\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3269 - accuracy: 0.1032\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3249 - accuracy: 0.1045\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3232 - accuracy: 0.1054\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3215 - accuracy: 0.1063\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3201 - accuracy: 0.1074\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3187 - accuracy: 0.1089\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3175 - accuracy: 0.1102\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3164 - accuracy: 0.1110\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3153 - accuracy: 0.1124\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3144 - accuracy: 0.1139\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3135 - accuracy: 0.1151\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3126 - accuracy: 0.1161\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3119 - accuracy: 0.1165\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3111 - accuracy: 0.1171\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3105 - accuracy: 0.1178\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3099 - accuracy: 0.1183\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3093 - accuracy: 0.1194\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3087 - accuracy: 0.1203\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3082 - accuracy: 0.1207\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3077 - accuracy: 0.1207\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3073 - accuracy: 0.1209\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3069 - accuracy: 0.1210\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3064 - accuracy: 0.1216\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3061 - accuracy: 0.1212\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3057 - accuracy: 0.1210\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3054 - accuracy: 0.1214\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3050 - accuracy: 0.1216\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3047 - accuracy: 0.1218\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3044 - accuracy: 0.1216\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3042 - accuracy: 0.1221\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3039 - accuracy: 0.1225\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3036 - accuracy: 0.1229\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3034 - accuracy: 0.1232\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3032 - accuracy: 0.1231\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3029 - accuracy: 0.1233\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3027 - accuracy: 0.1233\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3025 - accuracy: 0.1241\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3024 - accuracy: 0.1243\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3022 - accuracy: 0.1245\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3020 - accuracy: 0.1240\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3018 - accuracy: 0.1241\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3017 - accuracy: 0.1239\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3015 - accuracy: 0.1244\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3014 - accuracy: 0.1245\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3012 - accuracy: 0.1248\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3011 - accuracy: 0.1245\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3009 - accuracy: 0.1245\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3008 - accuracy: 0.1245\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3007 - accuracy: 0.1244\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3006 - accuracy: 0.1249\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3005 - accuracy: 0.1250\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3004 - accuracy: 0.1252\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3002 - accuracy: 0.1251\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3001 - accuracy: 0.1250\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3000 - accuracy: 0.1247\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2999 - accuracy: 0.1248\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2998 - accuracy: 0.1248\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2998 - accuracy: 0.1248\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2997 - accuracy: 0.1250\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2996 - accuracy: 0.1250\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2995 - accuracy: 0.1248\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2994 - accuracy: 0.1252\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2993 - accuracy: 0.1255\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2993 - accuracy: 0.1254\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2992 - accuracy: 0.1256\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2991 - accuracy: 0.1255\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2990 - accuracy: 0.1258\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2990 - accuracy: 0.1254\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2989 - accuracy: 0.1255\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2988 - accuracy: 0.1255\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2988 - accuracy: 0.1257\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2987 - accuracy: 0.1257\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2986 - accuracy: 0.1258\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2986 - accuracy: 0.1259\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2985 - accuracy: 0.1259\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2985 - accuracy: 0.1259\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2984 - accuracy: 0.1263\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2983 - accuracy: 0.1266\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2983 - accuracy: 0.1266\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2982 - accuracy: 0.1267\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2982 - accuracy: 0.1268\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2981 - accuracy: 0.1270\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2981 - accuracy: 0.1270\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2980 - accuracy: 0.1272\n",
      "Try 6/100: Best_val_acc: [2.297992467880249, 0.12754762172698975], lr: 5.828901406129966e-06, Lambda: 2.5119086227355624e-07\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3094 - accuracy: 0.1105\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2758 - accuracy: 0.1569\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2431 - accuracy: 0.2442\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1957 - accuracy: 0.3138\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1183 - accuracy: 0.3683\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0061 - accuracy: 0.4088\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8681 - accuracy: 0.4555\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7309 - accuracy: 0.4942\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6025 - accuracy: 0.5447\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5048 - accuracy: 0.5679\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4134 - accuracy: 0.5935\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3360 - accuracy: 0.6155\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2779 - accuracy: 0.6303\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2224 - accuracy: 0.6439\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1846 - accuracy: 0.6504\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1433 - accuracy: 0.6626\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1098 - accuracy: 0.6721\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0766 - accuracy: 0.6832\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0626 - accuracy: 0.6828\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0449 - accuracy: 0.6886\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0103 - accuracy: 0.7003\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9887 - accuracy: 0.7033\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9683 - accuracy: 0.7126\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9565 - accuracy: 0.7170\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9415 - accuracy: 0.7193\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9280 - accuracy: 0.7235\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9110 - accuracy: 0.7288\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9012 - accuracy: 0.7295\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8794 - accuracy: 0.7388\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8611 - accuracy: 0.7437\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8620 - accuracy: 0.7452\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8539 - accuracy: 0.7433\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8481 - accuracy: 0.7463\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8223 - accuracy: 0.7547\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8102 - accuracy: 0.7585\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7967 - accuracy: 0.7630\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7819 - accuracy: 0.7675\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7719 - accuracy: 0.7691\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7644 - accuracy: 0.7733\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7570 - accuracy: 0.7733\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7544 - accuracy: 0.7740\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7379 - accuracy: 0.7794\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7276 - accuracy: 0.7837\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7197 - accuracy: 0.7853\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7189 - accuracy: 0.7832\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7017 - accuracy: 0.7905\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7028 - accuracy: 0.7905\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7025 - accuracy: 0.7891\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6877 - accuracy: 0.7938\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6781 - accuracy: 0.7974\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6770 - accuracy: 0.7958\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6698 - accuracy: 0.7996\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6544 - accuracy: 0.8055\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6447 - accuracy: 0.8087\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6549 - accuracy: 0.8035\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6383 - accuracy: 0.8103\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6403 - accuracy: 0.8080\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6337 - accuracy: 0.8108\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6263 - accuracy: 0.8135\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6357 - accuracy: 0.8091\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6153 - accuracy: 0.8161\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6154 - accuracy: 0.8158\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6024 - accuracy: 0.8212\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5979 - accuracy: 0.8220\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5973 - accuracy: 0.8215\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5915 - accuracy: 0.8216\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5995 - accuracy: 0.8204\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5864 - accuracy: 0.8246\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5690 - accuracy: 0.8298\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5759 - accuracy: 0.8263\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5783 - accuracy: 0.8244\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5689 - accuracy: 0.8284\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5534 - accuracy: 0.8340\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5553 - accuracy: 0.8339\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5451 - accuracy: 0.8376\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5612 - accuracy: 0.8312\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5454 - accuracy: 0.8363\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5363 - accuracy: 0.8392\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5329 - accuracy: 0.8418\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5277 - accuracy: 0.8424\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5376 - accuracy: 0.8374\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5325 - accuracy: 0.8400\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5246 - accuracy: 0.8419\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5345 - accuracy: 0.8397\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5325 - accuracy: 0.8410\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5077 - accuracy: 0.8491\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5062 - accuracy: 0.8470\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5099 - accuracy: 0.8468\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5167 - accuracy: 0.8433\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5037 - accuracy: 0.8486\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4888 - accuracy: 0.8547\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4933 - accuracy: 0.8527\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4959 - accuracy: 0.8509\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4978 - accuracy: 0.8502\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4863 - accuracy: 0.8548\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4854 - accuracy: 0.8536\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4920 - accuracy: 0.8510\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4908 - accuracy: 0.8522\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4747 - accuracy: 0.8579\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4703 - accuracy: 0.8580\n",
      "Try 7/100: Best_val_acc: [0.4598352313041687, 0.8630714416503906], lr: 0.010766925202373604, Lambda: 6.092712902694874e-07\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3212 - accuracy: 0.0934\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3041 - accuracy: 0.1125\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2991 - accuracy: 0.1190\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2950 - accuracy: 0.1314\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2914 - accuracy: 0.1405\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2883 - accuracy: 0.1470\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2850 - accuracy: 0.1557\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2815 - accuracy: 0.1650\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2781 - accuracy: 0.1734\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2748 - accuracy: 0.1820\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2714 - accuracy: 0.1888\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2678 - accuracy: 0.1998\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2644 - accuracy: 0.2072\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2606 - accuracy: 0.2191\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2568 - accuracy: 0.2276\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2528 - accuracy: 0.2358\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2487 - accuracy: 0.2485\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2442 - accuracy: 0.2515\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2395 - accuracy: 0.2642\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2350 - accuracy: 0.2755\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2300 - accuracy: 0.2863\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2248 - accuracy: 0.2910\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2194 - accuracy: 0.3026\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2135 - accuracy: 0.3161\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2078 - accuracy: 0.3162\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2012 - accuracy: 0.3317\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1947 - accuracy: 0.3372\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1877 - accuracy: 0.3419\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1801 - accuracy: 0.3566\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1726 - accuracy: 0.3608\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1646 - accuracy: 0.3700\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1565 - accuracy: 0.3725\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1475 - accuracy: 0.3811\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1384 - accuracy: 0.3873\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1289 - accuracy: 0.3946\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1188 - accuracy: 0.4031\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1084 - accuracy: 0.4062\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0977 - accuracy: 0.4099\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0865 - accuracy: 0.4151\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0751 - accuracy: 0.4231\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0627 - accuracy: 0.4268\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0505 - accuracy: 0.4345\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0376 - accuracy: 0.4358\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0247 - accuracy: 0.4437\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0109 - accuracy: 0.4475\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9976 - accuracy: 0.4494\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9833 - accuracy: 0.4582\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9693 - accuracy: 0.4599\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9548 - accuracy: 0.4664\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9403 - accuracy: 0.4708\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.9257 - accuracy: 0.4723\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9108 - accuracy: 0.4772\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8956 - accuracy: 0.4826\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8809 - accuracy: 0.4858\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8662 - accuracy: 0.4902\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8511 - accuracy: 0.4962\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8363 - accuracy: 0.4985\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8214 - accuracy: 0.5041\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8071 - accuracy: 0.5056\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7924 - accuracy: 0.5126\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7783 - accuracy: 0.5129\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7636 - accuracy: 0.5211\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7496 - accuracy: 0.5235\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7355 - accuracy: 0.5294\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7216 - accuracy: 0.5323\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7084 - accuracy: 0.5359\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6950 - accuracy: 0.5391\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6816 - accuracy: 0.5447\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6690 - accuracy: 0.5485\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6569 - accuracy: 0.5483\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6437 - accuracy: 0.5550\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6318 - accuracy: 0.5580\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6195 - accuracy: 0.5609\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6076 - accuracy: 0.5651\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5964 - accuracy: 0.5688\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5848 - accuracy: 0.5712\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5733 - accuracy: 0.5756\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5622 - accuracy: 0.5785\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5519 - accuracy: 0.5817\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5409 - accuracy: 0.5846\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5308 - accuracy: 0.5860\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5201 - accuracy: 0.5897\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5099 - accuracy: 0.5926\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5001 - accuracy: 0.5946\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4899 - accuracy: 0.5969\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4812 - accuracy: 0.5994\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4714 - accuracy: 0.6024\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4617 - accuracy: 0.6052\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4523 - accuracy: 0.6067\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4437 - accuracy: 0.6095\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.4343 - accuracy: 0.6110\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4256 - accuracy: 0.6131\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4176 - accuracy: 0.6165\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4088 - accuracy: 0.6175\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4001 - accuracy: 0.6200\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3921 - accuracy: 0.6215\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3841 - accuracy: 0.6232\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3761 - accuracy: 0.6265\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3683 - accuracy: 0.6269\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3605 - accuracy: 0.6295\n",
      "Try 8/100: Best_val_acc: [1.3562575578689575, 0.6326666474342346], lr: 0.001068064149868944, Lambda: 0.00020247409365217612\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0993\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 2s 54ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 2s 56ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 54ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: nan - accuracy: 0.0997\n",
      "Try 9/100: Best_val_acc: [nan, 0.09966666996479034], lr: 49.50654415564732, Lambda: 2.459257070710422e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,10):\n",
    "    lr = math.pow(10, np.random.uniform(-7.0, 3.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
    "    best_acc = train_and_test_loop1(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3TizLDg8s-3"
   },
   "source": [
    "\n",
    "**As you can see from above, Case 1, 7 and 8 yields good accuracy. It is better to focus on those values for learning rate and Lambda**\n",
    "\n",
    "**Now run finer search**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ti3Q0eST8YaN",
    "outputId": "e2f38f6b-77f3-464a-a130-3f0724dd16a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4458 - accuracy: 0.0977\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.4207 - accuracy: 0.1136\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.4159 - accuracy: 0.1260\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.4119 - accuracy: 0.1357\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4084 - accuracy: 0.1401\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4052 - accuracy: 0.1506\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4024 - accuracy: 0.1566\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4000 - accuracy: 0.1612\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3976 - accuracy: 0.1658\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3953 - accuracy: 0.1704\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3930 - accuracy: 0.1734\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 2.3908 - accuracy: 0.1777\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3885 - accuracy: 0.1808\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3863 - accuracy: 0.1854\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3839 - accuracy: 0.1877\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3816 - accuracy: 0.1960\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3793 - accuracy: 0.1955\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3770 - accuracy: 0.2005\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3747 - accuracy: 0.2071\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3725 - accuracy: 0.2091\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3701 - accuracy: 0.2141\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3677 - accuracy: 0.2150\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3653 - accuracy: 0.2261\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3628 - accuracy: 0.2264\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3603 - accuracy: 0.2341\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3577 - accuracy: 0.2391\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3552 - accuracy: 0.2421\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3526 - accuracy: 0.2421\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3500 - accuracy: 0.2558\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3475 - accuracy: 0.2528\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3449 - accuracy: 0.2571\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3421 - accuracy: 0.2624\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3393 - accuracy: 0.2712\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3365 - accuracy: 0.2706\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3336 - accuracy: 0.2776\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3307 - accuracy: 0.2785\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3278 - accuracy: 0.2873\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3249 - accuracy: 0.2886\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3220 - accuracy: 0.2940\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3187 - accuracy: 0.2945\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3156 - accuracy: 0.3042\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3124 - accuracy: 0.3090\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3092 - accuracy: 0.3097\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3060 - accuracy: 0.3130\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3025 - accuracy: 0.3195\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2991 - accuracy: 0.3192\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2955 - accuracy: 0.3282\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2920 - accuracy: 0.3275\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2883 - accuracy: 0.3337\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2847 - accuracy: 0.3359\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2808 - accuracy: 0.3417\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2769 - accuracy: 0.3439\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2729 - accuracy: 0.3494\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2688 - accuracy: 0.3523\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2647 - accuracy: 0.3537\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2604 - accuracy: 0.3596\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2561 - accuracy: 0.3597\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2515 - accuracy: 0.3647\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2469 - accuracy: 0.3663\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2423 - accuracy: 0.3717\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2373 - accuracy: 0.3757\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2325 - accuracy: 0.3751\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2275 - accuracy: 0.3810\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2224 - accuracy: 0.3828\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2175 - accuracy: 0.3872\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2120 - accuracy: 0.3885\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2070 - accuracy: 0.3907\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2014 - accuracy: 0.3933\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1959 - accuracy: 0.3949\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1904 - accuracy: 0.3961\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1846 - accuracy: 0.4019\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1789 - accuracy: 0.4011\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1730 - accuracy: 0.4046\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1669 - accuracy: 0.4087\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1608 - accuracy: 0.4085\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1547 - accuracy: 0.4110\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1484 - accuracy: 0.4141\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1421 - accuracy: 0.4157\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1357 - accuracy: 0.4179\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1291 - accuracy: 0.4188\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1224 - accuracy: 0.4234\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1158 - accuracy: 0.4241\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1090 - accuracy: 0.4259\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1021 - accuracy: 0.4267\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0953 - accuracy: 0.4302\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0883 - accuracy: 0.4328\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0812 - accuracy: 0.4360\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0742 - accuracy: 0.4357\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0671 - accuracy: 0.4397\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0599 - accuracy: 0.4393\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0526 - accuracy: 0.4419\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0455 - accuracy: 0.4447\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0381 - accuracy: 0.4482\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0310 - accuracy: 0.4502\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0238 - accuracy: 0.4520\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0165 - accuracy: 0.4517\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0091 - accuracy: 0.4564\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0019 - accuracy: 0.4547\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.9947 - accuracy: 0.4586\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9872 - accuracy: 0.4620\n",
      "Try 1/100: Best_val_acc: [1.9831385612487793, 0.4618571400642395], lr: 0.0006403156555384723, Lambda: 0.006054442366188883\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3164 - accuracy: 0.1093\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2931 - accuracy: 0.1416\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2768 - accuracy: 0.1740\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2588 - accuracy: 0.2018\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2359 - accuracy: 0.2480\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2065 - accuracy: 0.2963\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1703 - accuracy: 0.3293\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1251 - accuracy: 0.3563\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0701 - accuracy: 0.3834\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0018 - accuracy: 0.4273\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9285 - accuracy: 0.4483\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.8496 - accuracy: 0.4767\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7716 - accuracy: 0.5024\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7003 - accuracy: 0.5159\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6320 - accuracy: 0.5400\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5670 - accuracy: 0.5644\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5121 - accuracy: 0.5788\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4616 - accuracy: 0.5914\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 2s 44ms/step - loss: 1.4113 - accuracy: 0.6070\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 1.3721 - accuracy: 0.6159\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 1.3338 - accuracy: 0.6272\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 1.3014 - accuracy: 0.6332\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2783 - accuracy: 0.6357\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2466 - accuracy: 0.6457\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2209 - accuracy: 0.6512\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1973 - accuracy: 0.6586\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1766 - accuracy: 0.6652\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1616 - accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1405 - accuracy: 0.6734\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1250 - accuracy: 0.6767\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1107 - accuracy: 0.6807\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0982 - accuracy: 0.6836\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0852 - accuracy: 0.6887\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0689 - accuracy: 0.6943\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0590 - accuracy: 0.6955\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0467 - accuracy: 0.6988\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0357 - accuracy: 0.7026\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0264 - accuracy: 0.7043\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0185 - accuracy: 0.7069\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0046 - accuracy: 0.7124\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0048 - accuracy: 0.7091\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9911 - accuracy: 0.7146\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9792 - accuracy: 0.7181\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9808 - accuracy: 0.7164\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9616 - accuracy: 0.7251\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9540 - accuracy: 0.7256\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9430 - accuracy: 0.7297\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9404 - accuracy: 0.7317\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9321 - accuracy: 0.7334\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9194 - accuracy: 0.7372\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9176 - accuracy: 0.7387\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9109 - accuracy: 0.7403\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8979 - accuracy: 0.7444\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8934 - accuracy: 0.7441\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8856 - accuracy: 0.7487\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8818 - accuracy: 0.7480\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8706 - accuracy: 0.7530\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8664 - accuracy: 0.7551\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8590 - accuracy: 0.7569\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8526 - accuracy: 0.7580\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8459 - accuracy: 0.7600\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8428 - accuracy: 0.7604\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8385 - accuracy: 0.7620\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8300 - accuracy: 0.7656\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8257 - accuracy: 0.7675\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8166 - accuracy: 0.7704\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8151 - accuracy: 0.7694\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8077 - accuracy: 0.7719\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8053 - accuracy: 0.7737\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8021 - accuracy: 0.7734\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7918 - accuracy: 0.7797\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7880 - accuracy: 0.7789\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7835 - accuracy: 0.7806\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7770 - accuracy: 0.7813\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7714 - accuracy: 0.7842\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7707 - accuracy: 0.7836\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7723 - accuracy: 0.7827\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7564 - accuracy: 0.7893\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7541 - accuracy: 0.7904\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7477 - accuracy: 0.7922\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7454 - accuracy: 0.7932\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7393 - accuracy: 0.7953\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7372 - accuracy: 0.7944\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7367 - accuracy: 0.7953\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7282 - accuracy: 0.7979\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7264 - accuracy: 0.7984\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7188 - accuracy: 0.8015\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7163 - accuracy: 0.8015\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7109 - accuracy: 0.8031\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7099 - accuracy: 0.8048\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7041 - accuracy: 0.8052\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7028 - accuracy: 0.8073\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7109 - accuracy: 0.8028\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6964 - accuracy: 0.8067\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6966 - accuracy: 0.8079\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6881 - accuracy: 0.8105\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6827 - accuracy: 0.8124\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6833 - accuracy: 0.8113\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6784 - accuracy: 0.8140\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6782 - accuracy: 0.8136\n",
      "Try 2/100: Best_val_acc: [0.6593219041824341, 0.8213571310043335], lr: 0.005743913963023006, Lambda: 0.0005585844063412421\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.4605 - accuracy: 0.1054\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4394 - accuracy: 0.1244\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4265 - accuracy: 0.1437\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.4148 - accuracy: 0.1611\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.4034 - accuracy: 0.1840\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3916 - accuracy: 0.2064\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.3798 - accuracy: 0.2352\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3678 - accuracy: 0.2545\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3552 - accuracy: 0.2822\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3423 - accuracy: 0.2974\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3281 - accuracy: 0.3177\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3133 - accuracy: 0.3361\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2974 - accuracy: 0.3501\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2797 - accuracy: 0.3673\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2607 - accuracy: 0.3768\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2395 - accuracy: 0.3871\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2164 - accuracy: 0.3958\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1912 - accuracy: 0.4070\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1647 - accuracy: 0.4106\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1359 - accuracy: 0.4191\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1054 - accuracy: 0.4294\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0737 - accuracy: 0.4380\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0412 - accuracy: 0.4457\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0087 - accuracy: 0.4538\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9759 - accuracy: 0.4664\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9428 - accuracy: 0.4738\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9110 - accuracy: 0.4870\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8808 - accuracy: 0.4963\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8508 - accuracy: 0.5062\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8244 - accuracy: 0.5126\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7969 - accuracy: 0.5251\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.7694 - accuracy: 0.5345\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7445 - accuracy: 0.5424\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7216 - accuracy: 0.5509\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6973 - accuracy: 0.5604\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6761 - accuracy: 0.5659\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6542 - accuracy: 0.5736\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6333 - accuracy: 0.5812\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6141 - accuracy: 0.5852\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5944 - accuracy: 0.5925\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5776 - accuracy: 0.5940\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5594 - accuracy: 0.6011\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5426 - accuracy: 0.6021\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5276 - accuracy: 0.6083\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5118 - accuracy: 0.6113\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4968 - accuracy: 0.6155\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4824 - accuracy: 0.6193\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.4683 - accuracy: 0.6232\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4564 - accuracy: 0.6253\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.4429 - accuracy: 0.6287\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4316 - accuracy: 0.6316\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4189 - accuracy: 0.6361\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4090 - accuracy: 0.6386\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3987 - accuracy: 0.6405\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3883 - accuracy: 0.6432\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3776 - accuracy: 0.6465\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3682 - accuracy: 0.6495\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3621 - accuracy: 0.6493\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3525 - accuracy: 0.6503\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3422 - accuracy: 0.6567\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3347 - accuracy: 0.6577\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3261 - accuracy: 0.6593\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3191 - accuracy: 0.6606\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3118 - accuracy: 0.6628\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3033 - accuracy: 0.6663\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2945 - accuracy: 0.6688\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2881 - accuracy: 0.6700\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2821 - accuracy: 0.6718\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2766 - accuracy: 0.6719\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2684 - accuracy: 0.6755\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2618 - accuracy: 0.6770\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2554 - accuracy: 0.6792\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2518 - accuracy: 0.6774\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2446 - accuracy: 0.6796\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2382 - accuracy: 0.6828\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2329 - accuracy: 0.6846\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2270 - accuracy: 0.6834\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2214 - accuracy: 0.6855\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.2175 - accuracy: 0.6875\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2120 - accuracy: 0.6887\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2046 - accuracy: 0.6922\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1992 - accuracy: 0.6929\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1945 - accuracy: 0.6948\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1912 - accuracy: 0.6942\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1843 - accuracy: 0.6966\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1804 - accuracy: 0.6981\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1748 - accuracy: 0.6997\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1704 - accuracy: 0.7001\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1672 - accuracy: 0.7009\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1603 - accuracy: 0.7037\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1559 - accuracy: 0.7042\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1531 - accuracy: 0.7044\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1466 - accuracy: 0.7087\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1447 - accuracy: 0.7083\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1391 - accuracy: 0.7100\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1337 - accuracy: 0.7112\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1285 - accuracy: 0.7140\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1258 - accuracy: 0.7149\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1219 - accuracy: 0.7146\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1186 - accuracy: 0.7164\n",
      "Try 3/100: Best_val_acc: [1.112365484237671, 0.7177857160568237], lr: 0.0030860613712362798, Lambda: 0.00798636493858862\n",
      "\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3052 - accuracy: 0.1128\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.2821 - accuracy: 0.1558\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2646 - accuracy: 0.1937\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2427 - accuracy: 0.2407\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2121 - accuracy: 0.2817\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1675 - accuracy: 0.3241\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1075 - accuracy: 0.3620\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.0283 - accuracy: 0.4110\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9328 - accuracy: 0.4469\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.8309 - accuracy: 0.4764\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.7261 - accuracy: 0.5093\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.6298 - accuracy: 0.5394\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.5478 - accuracy: 0.5622\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4781 - accuracy: 0.5804\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.4151 - accuracy: 0.5967\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.3606 - accuracy: 0.6133\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3069 - accuracy: 0.6287\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2626 - accuracy: 0.6400\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2278 - accuracy: 0.6472\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1952 - accuracy: 0.6551\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1646 - accuracy: 0.6642\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1345 - accuracy: 0.6718\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1137 - accuracy: 0.6762\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0929 - accuracy: 0.6821\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0754 - accuracy: 0.6860\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0474 - accuracy: 0.6937\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0386 - accuracy: 0.6937\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0285 - accuracy: 0.6964\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0152 - accuracy: 0.6999\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9910 - accuracy: 0.7061\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9821 - accuracy: 0.7083\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9624 - accuracy: 0.7141\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9396 - accuracy: 0.7235\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9268 - accuracy: 0.7267\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9135 - accuracy: 0.7296\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9078 - accuracy: 0.7291\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8989 - accuracy: 0.7336\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8829 - accuracy: 0.7393\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8676 - accuracy: 0.7439\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8619 - accuracy: 0.7445\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8532 - accuracy: 0.7473\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8445 - accuracy: 0.7496\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8262 - accuracy: 0.7575\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8197 - accuracy: 0.7592\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8234 - accuracy: 0.7549\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8146 - accuracy: 0.7598\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8119 - accuracy: 0.7591\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7845 - accuracy: 0.7691\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7791 - accuracy: 0.7720\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7728 - accuracy: 0.7703\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7726 - accuracy: 0.7703\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7520 - accuracy: 0.7783\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7449 - accuracy: 0.7811\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7395 - accuracy: 0.7826\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7382 - accuracy: 0.7832\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7181 - accuracy: 0.7890\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7143 - accuracy: 0.7900\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7125 - accuracy: 0.7904\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7140 - accuracy: 0.7885\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6993 - accuracy: 0.7945\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7085 - accuracy: 0.7915\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6941 - accuracy: 0.7959\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6868 - accuracy: 0.7974\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6841 - accuracy: 0.7995\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6720 - accuracy: 0.8017\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6619 - accuracy: 0.8065\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6542 - accuracy: 0.8090\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6548 - accuracy: 0.8069\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6496 - accuracy: 0.8090\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6440 - accuracy: 0.8108\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6398 - accuracy: 0.8129\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6339 - accuracy: 0.8152\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6294 - accuracy: 0.8158\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6244 - accuracy: 0.8171\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6225 - accuracy: 0.8176\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6347 - accuracy: 0.8119\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6129 - accuracy: 0.8210\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6054 - accuracy: 0.8228\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6027 - accuracy: 0.8222\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6107 - accuracy: 0.8205\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5993 - accuracy: 0.8242\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5939 - accuracy: 0.8254\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5862 - accuracy: 0.8296\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5785 - accuracy: 0.8311\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5869 - accuracy: 0.8280\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5778 - accuracy: 0.8308\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5801 - accuracy: 0.8291\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5793 - accuracy: 0.8300\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5741 - accuracy: 0.8323\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5601 - accuracy: 0.8360\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5667 - accuracy: 0.8337\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5620 - accuracy: 0.8355\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5571 - accuracy: 0.8379\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5603 - accuracy: 0.8341\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5506 - accuracy: 0.8383\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5532 - accuracy: 0.8374\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5554 - accuracy: 0.8383\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5406 - accuracy: 0.8425\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5486 - accuracy: 0.8391\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5328 - accuracy: 0.8446\n",
      "Try 4/100: Best_val_acc: [0.5283169746398926, 0.8464761972427368], lr: 0.007480207320878181, Lambda: 2.760154558557418e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,5):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, -2.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,-2))\n",
    "    best_acc = train_and_test_loop1(100, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fetvtVA8-DQ"
   },
   "source": [
    "Running deep with lr=0.007 and Lambda=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "T8jZRqQt88PY",
    "outputId": "6c3747c5-3232-4189-9421-0866437c5274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.3025 - accuracy: 0.1238\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2796 - accuracy: 0.1705\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2584 - accuracy: 0.2173\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.2289 - accuracy: 0.2770\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.1905 - accuracy: 0.3229\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 2.1372 - accuracy: 0.3697\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 2.0691 - accuracy: 0.3978\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.9831 - accuracy: 0.4262\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8831 - accuracy: 0.4592\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.7825 - accuracy: 0.4870\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6938 - accuracy: 0.5099\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.6070 - accuracy: 0.5411\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5292 - accuracy: 0.5635\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4638 - accuracy: 0.5849\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.4027 - accuracy: 0.6021\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3569 - accuracy: 0.6123\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.3084 - accuracy: 0.6258\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2689 - accuracy: 0.6344\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2281 - accuracy: 0.6477\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2001 - accuracy: 0.6528\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1712 - accuracy: 0.6590\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1448 - accuracy: 0.6670\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.1194 - accuracy: 0.6723\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0990 - accuracy: 0.6783\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0822 - accuracy: 0.6813\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0617 - accuracy: 0.6872\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0379 - accuracy: 0.6958\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0245 - accuracy: 0.6973\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0115 - accuracy: 0.7001\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9926 - accuracy: 0.7073\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9813 - accuracy: 0.7099\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9680 - accuracy: 0.7139\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9531 - accuracy: 0.7196\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9386 - accuracy: 0.7240\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9270 - accuracy: 0.7256\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9187 - accuracy: 0.7287\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9063 - accuracy: 0.7312\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8902 - accuracy: 0.7369\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8832 - accuracy: 0.7398\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8716 - accuracy: 0.7424\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8606 - accuracy: 0.7457\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8535 - accuracy: 0.7482\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8495 - accuracy: 0.7477\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8338 - accuracy: 0.7520\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8184 - accuracy: 0.7587\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8127 - accuracy: 0.7600\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8031 - accuracy: 0.7629\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7959 - accuracy: 0.7650\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7896 - accuracy: 0.7664\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7753 - accuracy: 0.7710\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7706 - accuracy: 0.7738\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7665 - accuracy: 0.7735\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7504 - accuracy: 0.7795\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7433 - accuracy: 0.7812\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7414 - accuracy: 0.7812\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7333 - accuracy: 0.7839\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7277 - accuracy: 0.7850\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7199 - accuracy: 0.7864\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7128 - accuracy: 0.7901\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7068 - accuracy: 0.7911\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7031 - accuracy: 0.7929\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6946 - accuracy: 0.7963\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6926 - accuracy: 0.7970\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6832 - accuracy: 0.7982\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6732 - accuracy: 0.8019\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6716 - accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6744 - accuracy: 0.8005\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6661 - accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6518 - accuracy: 0.8092\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6590 - accuracy: 0.8044\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6482 - accuracy: 0.8084\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6517 - accuracy: 0.8075\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6397 - accuracy: 0.8115\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6341 - accuracy: 0.8129\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6346 - accuracy: 0.8135\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6254 - accuracy: 0.8165\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6190 - accuracy: 0.8188\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6142 - accuracy: 0.8198\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6144 - accuracy: 0.8185\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6123 - accuracy: 0.8200\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6116 - accuracy: 0.8194\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5980 - accuracy: 0.8241\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6053 - accuracy: 0.8219\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6023 - accuracy: 0.8242\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5946 - accuracy: 0.8248\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5899 - accuracy: 0.8266\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5820 - accuracy: 0.8304\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5757 - accuracy: 0.8313\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5791 - accuracy: 0.8290\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5727 - accuracy: 0.8323\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5698 - accuracy: 0.8323\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5724 - accuracy: 0.8331\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5636 - accuracy: 0.8341\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5553 - accuracy: 0.8370\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5568 - accuracy: 0.8367\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5520 - accuracy: 0.8379\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5531 - accuracy: 0.8367\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5559 - accuracy: 0.8360\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5530 - accuracy: 0.8361\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5479 - accuracy: 0.8379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5327198505401611, 0.8442857265472412]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 7e-3\n",
    "Lambda = 1e-5\n",
    "train_and_test_loop1(100, lr, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQB_F3H_O6J3"
   },
   "source": [
    "Hence, we can see that using the learning rate around \n",
    "0.0075 and Lambda 1e-5 gives us a better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oSHg2tTOfTz"
   },
   "source": [
    "**5. Implement batch normalization for training the neural network**\n",
    "\n",
    ">   Create Sequential with Drop and Batch Normalization along with the hyperparameters that we recieved after tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjA10uFur6tM"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heVrq9Cj8ByI"
   },
   "outputs": [],
   "source": [
    "#Open the file as readonly/content/drive/My Drive/SVHN_single_grey1.h5\n",
    "h5f = h5py.File('/content/drive/My Drive/SVHN_single_grey1.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htJ8xHpL8Bo5"
   },
   "outputs": [],
   "source": [
    "# Load the training, test and validation test\n",
    "X_train= h5f['X_train'][:]\n",
    "y_train1= h5f['y_train'][:]\n",
    "X_test= h5f['X_test'][:]\n",
    "y_test1= h5f['y_test'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hJoaj8sw8NUV",
    "outputId": "b3426cf9-d1f3-4b5c-e30d-f3b5f26e8570"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P3i3l8pu8RL5",
    "outputId": "d96a202c-24c2-4a06-87b0-745cf412a238"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 32, 32)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "kN_rtxqV8HfR",
    "outputId": "77404807-466a-40ab-9eab-982315ef89fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(42000,1024)\n",
    "print(X_train.shape)\n",
    "X_test = X_test.reshape(18000,1024)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "7uA-bc7e8aP6",
    "outputId": "67f38431-9ed0-4bac-a9fe-b3f75d7ca269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "YzwyI8Jm0Ymz",
    "outputId": "b69e1931-504c-4cd0-ee1e-66c879eceea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train1[10])\n",
    "y_train1 = tensorflow.keras.utils.to_categorical(y_train1, num_classes=10)\n",
    "y_test1 = tensorflow.keras.utils.to_categorical(y_test1, num_classes=10)\n",
    "print(y_train1[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FA4osIXe0RBT"
   },
   "outputs": [],
   "source": [
    "\n",
    "## hyperparameters\n",
    "iterations = 10\n",
    "Lambda=1e-5\n",
    "hidden_nodes = 722\n",
    "output_nodes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6wQS36yu_c4"
   },
   "outputs": [],
   "source": [
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(hidden_nodes, input_shape = (1024,), activation = 'relu'))\n",
    "model2.add(Dense(hidden_nodes, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10 , activation = 'softmax',kernel_regularizer=regularizers.l2(Lambda)))\n",
    "sgd = optimizers.Adam(lr = 0.0075)\n",
    "model2.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "zn3B4J4Stq-8",
    "outputId": "e8ed3a55-b7f7-4cb7-eaca-3349d61118d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 722)               740050    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 722)               522006    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 722)               2888      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 722)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                7230      \n",
      "=================================================================\n",
      "Total params: 1,272,174\n",
      "Trainable params: 1,270,730\n",
      "Non-trainable params: 1,444\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1Ad1THC_4HJB",
    "outputId": "4e8053ba-dd03-4138-f732-01f435b92eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 6s 152ms/step - loss: 2.5943 - accuracy: 0.1077 - val_loss: 3.3048 - val_accuracy: 0.0983\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 2.3193 - accuracy: 0.1285 - val_loss: 2.5239 - val_accuracy: 0.0982\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 2.2146 - accuracy: 0.1726 - val_loss: 2.8139 - val_accuracy: 0.1056\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 2.0123 - accuracy: 0.2500 - val_loss: 2.4650 - val_accuracy: 0.1246\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 1.8255 - accuracy: 0.3275 - val_loss: 2.1745 - val_accuracy: 0.2557\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 1.6900 - accuracy: 0.3919 - val_loss: 1.8553 - val_accuracy: 0.3566\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 1.5837 - accuracy: 0.4463 - val_loss: 1.7983 - val_accuracy: 0.3323\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 1.4379 - accuracy: 0.5090 - val_loss: 3.5586 - val_accuracy: 0.1991\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 9s 226ms/step - loss: 1.3758 - accuracy: 0.5361 - val_loss: 1.8039 - val_accuracy: 0.3473\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 1.3119 - accuracy: 0.5630 - val_loss: 1.4522 - val_accuracy: 0.5079\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 1.2436 - accuracy: 0.5924 - val_loss: 1.4831 - val_accuracy: 0.4708\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 1.1913 - accuracy: 0.6124 - val_loss: 1.6527 - val_accuracy: 0.4264\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 1.1570 - accuracy: 0.6249 - val_loss: 1.9262 - val_accuracy: 0.5061\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 1.1049 - accuracy: 0.6465 - val_loss: 1.4959 - val_accuracy: 0.5004\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 1.0510 - accuracy: 0.6659 - val_loss: 1.7146 - val_accuracy: 0.4242\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 1.0100 - accuracy: 0.6832 - val_loss: 1.2847 - val_accuracy: 0.6084\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.9473 - accuracy: 0.7017 - val_loss: 0.9784 - val_accuracy: 0.6888\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.9056 - accuracy: 0.7172 - val_loss: 1.6312 - val_accuracy: 0.5558\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.8795 - accuracy: 0.7256 - val_loss: 0.9549 - val_accuracy: 0.7049\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.8480 - accuracy: 0.7353 - val_loss: 0.8302 - val_accuracy: 0.7427\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.8108 - accuracy: 0.7487 - val_loss: 0.9141 - val_accuracy: 0.7138\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.7962 - accuracy: 0.7515 - val_loss: 0.8066 - val_accuracy: 0.7531\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.7647 - accuracy: 0.7617 - val_loss: 0.7701 - val_accuracy: 0.7642\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.7617 - accuracy: 0.7646 - val_loss: 0.8520 - val_accuracy: 0.7339\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.7512 - accuracy: 0.7677 - val_loss: 0.7401 - val_accuracy: 0.7743\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.7262 - accuracy: 0.7752 - val_loss: 0.7684 - val_accuracy: 0.7648\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.6974 - accuracy: 0.7835 - val_loss: 0.7130 - val_accuracy: 0.7879\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.7075 - accuracy: 0.7802 - val_loss: 0.7995 - val_accuracy: 0.7699\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6885 - accuracy: 0.7860 - val_loss: 0.7701 - val_accuracy: 0.7646\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.6751 - accuracy: 0.7897 - val_loss: 0.7298 - val_accuracy: 0.7793\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6581 - accuracy: 0.7959 - val_loss: 0.7538 - val_accuracy: 0.7746\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6559 - accuracy: 0.7939 - val_loss: 0.7283 - val_accuracy: 0.7855\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.6440 - accuracy: 0.7990 - val_loss: 0.7439 - val_accuracy: 0.7798\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.6463 - accuracy: 0.7994 - val_loss: 0.6707 - val_accuracy: 0.7989\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6433 - accuracy: 0.7998 - val_loss: 0.7701 - val_accuracy: 0.7783\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6357 - accuracy: 0.8012 - val_loss: 0.7193 - val_accuracy: 0.7854\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6256 - accuracy: 0.8050 - val_loss: 0.7062 - val_accuracy: 0.7831\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.6142 - accuracy: 0.8079 - val_loss: 0.7014 - val_accuracy: 0.7925\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.6093 - accuracy: 0.8100 - val_loss: 0.7050 - val_accuracy: 0.7856\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6179 - accuracy: 0.8056 - val_loss: 0.6510 - val_accuracy: 0.8088\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.6080 - accuracy: 0.8101 - val_loss: 0.7340 - val_accuracy: 0.7681\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5962 - accuracy: 0.8147 - val_loss: 0.7260 - val_accuracy: 0.7840\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.6092 - accuracy: 0.8083 - val_loss: 0.6797 - val_accuracy: 0.7961\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5908 - accuracy: 0.8160 - val_loss: 0.6639 - val_accuracy: 0.8026\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5828 - accuracy: 0.8180 - val_loss: 0.6693 - val_accuracy: 0.8054\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 0.5924 - accuracy: 0.8137 - val_loss: 0.6955 - val_accuracy: 0.7914\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5685 - accuracy: 0.8211 - val_loss: 0.6298 - val_accuracy: 0.8091\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5821 - accuracy: 0.8180 - val_loss: 0.6998 - val_accuracy: 0.7985\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 6s 152ms/step - loss: 0.5620 - accuracy: 0.8229 - val_loss: 0.6561 - val_accuracy: 0.8028\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.5769 - accuracy: 0.8203 - val_loss: 0.7249 - val_accuracy: 0.7859\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5699 - accuracy: 0.8202 - val_loss: 0.6558 - val_accuracy: 0.8067\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5650 - accuracy: 0.8221 - val_loss: 0.6878 - val_accuracy: 0.8043\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5486 - accuracy: 0.8289 - val_loss: 0.6757 - val_accuracy: 0.7974\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5672 - accuracy: 0.8205 - val_loss: 0.7655 - val_accuracy: 0.7797\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5576 - accuracy: 0.8245 - val_loss: 0.7284 - val_accuracy: 0.7806\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5535 - accuracy: 0.8236 - val_loss: 0.6512 - val_accuracy: 0.8116\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5583 - accuracy: 0.8238 - val_loss: 0.6619 - val_accuracy: 0.8077\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5430 - accuracy: 0.8265 - val_loss: 0.6810 - val_accuracy: 0.8038\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5534 - accuracy: 0.8250 - val_loss: 0.7106 - val_accuracy: 0.7882\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 0.5355 - accuracy: 0.8310 - val_loss: 0.6365 - val_accuracy: 0.8151\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5316 - accuracy: 0.8330 - val_loss: 0.6841 - val_accuracy: 0.8106\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5269 - accuracy: 0.8328 - val_loss: 0.6389 - val_accuracy: 0.8129\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5322 - accuracy: 0.8340 - val_loss: 0.6293 - val_accuracy: 0.8134\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5479 - accuracy: 0.8273 - val_loss: 0.6380 - val_accuracy: 0.8155\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.5263 - accuracy: 0.8339 - val_loss: 0.6321 - val_accuracy: 0.8096\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5349 - accuracy: 0.8313 - val_loss: 0.6429 - val_accuracy: 0.8169\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5207 - accuracy: 0.8354 - val_loss: 0.5977 - val_accuracy: 0.8238\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5278 - accuracy: 0.8322 - val_loss: 0.6726 - val_accuracy: 0.8062\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5351 - accuracy: 0.8310 - val_loss: 0.6439 - val_accuracy: 0.8071\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 0.5106 - accuracy: 0.8383 - val_loss: 0.6628 - val_accuracy: 0.8089\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5121 - accuracy: 0.8383 - val_loss: 0.6503 - val_accuracy: 0.8111\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5186 - accuracy: 0.8352 - val_loss: 0.6690 - val_accuracy: 0.8066\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5116 - accuracy: 0.8371 - val_loss: 0.6178 - val_accuracy: 0.8247\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5024 - accuracy: 0.8398 - val_loss: 0.6203 - val_accuracy: 0.8180\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 0.5113 - accuracy: 0.8367 - val_loss: 0.7164 - val_accuracy: 0.7942\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5059 - accuracy: 0.8412 - val_loss: 0.7204 - val_accuracy: 0.7952\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5136 - accuracy: 0.8373 - val_loss: 0.6216 - val_accuracy: 0.8249\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5029 - accuracy: 0.8412 - val_loss: 0.6116 - val_accuracy: 0.8233\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5029 - accuracy: 0.8391 - val_loss: 0.6204 - val_accuracy: 0.8221\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.5023 - accuracy: 0.8410 - val_loss: 0.6759 - val_accuracy: 0.8109\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5065 - accuracy: 0.8394 - val_loss: 0.6240 - val_accuracy: 0.8151\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.4983 - accuracy: 0.8425 - val_loss: 0.6509 - val_accuracy: 0.8162\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.5003 - accuracy: 0.8404 - val_loss: 0.6384 - val_accuracy: 0.8124\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.4937 - accuracy: 0.8433 - val_loss: 0.6565 - val_accuracy: 0.8091\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.5001 - accuracy: 0.8413 - val_loss: 0.6037 - val_accuracy: 0.8270\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4894 - accuracy: 0.8444 - val_loss: 0.6834 - val_accuracy: 0.8049\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4863 - accuracy: 0.8462 - val_loss: 0.6222 - val_accuracy: 0.8186\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4864 - accuracy: 0.8460 - val_loss: 0.7024 - val_accuracy: 0.8131\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.4892 - accuracy: 0.8441 - val_loss: 0.6586 - val_accuracy: 0.8093\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.4946 - accuracy: 0.8434 - val_loss: 0.6494 - val_accuracy: 0.8139\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.5102 - accuracy: 0.8354 - val_loss: 0.6472 - val_accuracy: 0.8187\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4791 - accuracy: 0.8474 - val_loss: 0.6312 - val_accuracy: 0.8156\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4757 - accuracy: 0.8482 - val_loss: 0.6245 - val_accuracy: 0.8201\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.4700 - accuracy: 0.8511 - val_loss: 0.6924 - val_accuracy: 0.8067\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4666 - accuracy: 0.8512 - val_loss: 0.6544 - val_accuracy: 0.8071\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4773 - accuracy: 0.8477 - val_loss: 0.6309 - val_accuracy: 0.8173\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4863 - accuracy: 0.8464 - val_loss: 0.6540 - val_accuracy: 0.8173\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.4843 - accuracy: 0.8461 - val_loss: 0.6155 - val_accuracy: 0.8242\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 6s 151ms/step - loss: 0.4690 - accuracy: 0.8498 - val_loss: 0.6199 - val_accuracy: 0.8238\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.4788 - accuracy: 0.8469 - val_loss: 0.6503 - val_accuracy: 0.8098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab5b0d1358>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train1,validation_data=(X_test,y_test1),epochs=100,batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2pmqFo9OTNs"
   },
   "source": [
    "**6. Print the classification accuracy metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FNGo8REH8UFI",
    "outputId": "292628ec-44e5-403e-c8d0-b4935427a079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44582027196884155, 0.8563809394836426]\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_train, y_train1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "4SBhwhRDNGzH",
    "outputId": "c1829350-bc02-4e85-f3dd-34e641f0b502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model : 0.8563809394836426 with loss 0.44582027196884155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model : {1} with loss {0}\\n\".format(score[0],score[1]))\n",
    "#\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tplaVHosN8ko"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SVHN - NN Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
